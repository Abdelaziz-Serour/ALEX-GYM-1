{"cells":[{"cell_type":"markdown","metadata":{"id":"eD7vpMS924a1"},"source":["This Notebook contains implementations of neural network models that process video frames and pose landmarks to classify actions and predict ratings.\n"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":22211,"status":"ok","timestamp":1734089108261,"user":{"displayName":"ai research","userId":"07349987832510586956"},"user_tz":-120},"id":"fwXbWGQOyJDD"},"outputs":[],"source":["import os\n","import json\n","\n","import cv2\n","import numpy as np\n","import pandas as pd\n","\n","from sklearn.model_selection import train_test_split\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","\n","from transformers import AutoImageProcessor, AutoModelForPreTraining"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1734089108262,"user":{"displayName":"ai research","userId":"07349987832510586956"},"user_tz":-120},"id":"FmdwF_C45U--","outputId":"31bf26e2-3486-4b91-927c-fa04b83ca76a"},"outputs":[{"name":"stdout","output_type":"stream","text":["CUDA is available. PyTorch can use the GPU.\n","Device name: Tesla T4\n"]}],"source":["# Check if CUDA (GPU support) is available\n","if torch.cuda.is_available():\n","    print(\"CUDA is available. PyTorch can use the GPU.\")\n","    print(f\"Device name: {torch.cuda.get_device_name(0)}\")\n","else:\n","    print(\"CUDA is not available. PyTorch is using the CPU.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":7,"status":"aborted","timestamp":1734097566314,"user":{"displayName":"ai research","userId":"07349987832510586956"},"user_tz":-120},"id":"KdOB4Yjz50De"},"outputs":[],"source":["base_path = \"/content/drive/MyDrive/Vision_GYM_Research/Data\"\n","LOG_DIR = \"/content/drive/MyDrive/Vision_GYM_Research/tensorboard_logs\""]},{"cell_type":"markdown","metadata":{"id":"GsKfIuDB2zsP"},"source":["## Functions\n","\n","### `load_and_resize_frames`\n","- **Description**: Loads and resizes video frames from specified file paths.\n","- **Parameters**:\n","  - `num_video_frontal`: Identifier for the video file.\n","  - `num_idx`: Index for the specific video segment.\n","  - `num_frames`: Number of frames to load.\n","  - `size`: Target size for resizing frames (default: (224, 224)).\n","- **Returns**: List of resized frames.\n","\n","### `extract_pose_landmarks`\n","- **Description**: Extracts pose landmarks from a list of video frames using MediaPipe.\n","- **Parameters**:\n","  - `video_frames`: List of frames (each of size [224, 224, 3]).\n","- **Returns**: Array of pose landmarks with shape [num_frames, 33, 3].\n"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":745,"status":"ok","timestamp":1734075077649,"user":{"displayName":"ai research","userId":"07349987832510586956"},"user_tz":-120},"id":"64pDhqby2ohg"},"outputs":[],"source":["def load_and_resize_frames(num_video, action, isFront, num_idx, num_frames, size=(224, 224)):\n","    \"\"\"\n","    Loads and resizes video frames from specified file paths based on the action type.\n","\n","    Args:\n","        num_video (int): Identifier for the video file.\n","        action (str): The action being performed ('deadlift', 'squat', 'lunges').\n","        isFront (int): 1 for frontal frames, 0 for lateral frames.\n","        num_idx (int): Index for the specific video segment.\n","        num_frames (int): Number of frames to load.\n","        size (tuple): Target size for resizing frames (default is (224, 224)).\n","\n","    Returns:\n","        list: A list of resized frames.\n","    \"\"\"\n","    frames = []\n","\n","    action_to_folder = {\n","        'Deadlift': 'Deadlift_Frames',\n","        'Squat': 'Squat_Frames',\n","        'lunges': 'Lunges_Frames'\n","    }\n","\n","    if action not in action_to_folder:\n","        raise ValueError(f\"Unknown action: {action}\")\n","\n","    base_folder = os.path.join(base_path, action_to_folder[action])\n","\n","    # Load and resize frames\n","    for i in range(1, num_frames + 1):\n","        path = os.path.join(base_folder, f\"{num_video}_idx_{num_idx}_{i}.jpg\")\n","        img = cv2.imread(path)\n","        if img is not None:\n","            img_resized = cv2.resize(img, size)\n","            frames.append(img_resized)\n","        else:\n","            print(f\"Warning: Could not load image at {path}\")\n","    return frames"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1734089202973,"user":{"displayName":"ai research","userId":"07349987832510586956"},"user_tz":-120},"id":"VP5bNKfpEyMD"},"outputs":[],"source":["def process_action_data(base_path, action_name):\n","    \"\"\"\n","    Process data for a specific action by loading the corresponding Excel and JSON files,\n","    adding pose data, and splitting into train, validation, and test sets.\n","\n","    Args:\n","        base_path (str): The base directory containing the files.\n","        action_name (str): The name of the action (e.g., 'squat', 'deadlift', 'lunges').\n","\n","    Returns:\n","        tuple: train_df, val_df, test_df DataFrames.\n","    \"\"\"\n","    # Load the Excel file\n","    excel_file = f\"{action_name}_edited.xlsx\"\n","    df = pd.read_excel(os.path.join(base_path, excel_file))\n","\n","    # Load the JSON files for front and lateral poses\n","    front_pose_file = f\"front_pose_{action_name}.json\"\n","    lat_pose_file = f\"lat_pose_{action_name}.json\"\n","\n","    def load_json_as_numpy(json_file):\n","        with open(json_file, 'r') as file:\n","            data = json.load(file)\n","        return np.array(data)\n","\n","    front_pose_array = load_json_as_numpy(os.path.join(base_path, front_pose_file))\n","    lat_pose_array = load_json_as_numpy(os.path.join(base_path, lat_pose_file))\n","\n","    # Ensure `front_pose` and `lat_pose` columns exist\n","    if 'front_pose' not in df.columns:\n","        df['front_pose'] = None\n","    if 'lat_pose' not in df.columns:\n","        df['lat_pose'] = None\n","\n","    # Assign the loaded arrays to the DataFrame if lengths match\n","    if len(front_pose_array) == len(df) and len(lat_pose_array) == len(df):\n","        df['front_pose'] = list(front_pose_array)\n","        df['lat_pose'] = list(lat_pose_array)\n","    else:\n","        raise ValueError(\"The length of the loaded arrays does not match the DataFrame.\")\n","\n","    # Shuffle the DataFrame\n","    df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n","\n","    # Define split ratios\n","    train_ratio, val_ratio, test_ratio = 0.7, 0.15, 0.15\n","\n","    # Calculate the number of samples for each set\n","    total_samples = len(df)\n","    train_size = int(total_samples * train_ratio)\n","    val_size = int(total_samples * val_ratio)\n","\n","    # Split the DataFrame\n","    train_df = df.iloc[:train_size]\n","    val_df = df.iloc[train_size:train_size + val_size]\n","    test_df = df.iloc[train_size + val_size:]\n","\n","    return train_df, val_df, test_df"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":7254,"status":"ok","timestamp":1734089493219,"user":{"displayName":"ai research","userId":"07349987832510586956"},"user_tz":-120},"id":"kHrmZE3a5U_C"},"outputs":[],"source":["train_df_squat, val_df_squat, test_df_squat = process_action_data(base_path, 'squat')\n","train_df_dead, val_df_dead, test_df_dead = process_action_data(base_path, 'deadlift')\n","train_df_lunge, val_df_lunge, test_df_lunge = process_action_data(base_path, 'lunges')\n","\n","\n","# Define the actions\n","actions = ['squat', 'deadlift', 'lunges']\n","\n","# Process data for each action and store results in dictionaries\n","splits = {action: process_action_data(base_path, action) for action in actions}\n","\n","# Concatenate and shuffle DataFrames for each split\n","train_df = pd.concat([splits[action][0] for action in actions]).sample(frac=1, random_state=1).reset_index(drop=True)\n","val_df = pd.concat([splits[action][1] for action in actions]).sample(frac=1, random_state=1).reset_index(drop=True)\n","test_df = pd.concat([splits[action][2] for action in actions]).sample(frac=1, random_state=1).reset_index(drop=True)"]},{"cell_type":"markdown","metadata":{"id":"TWS-aEv93AO-"},"source":["### `Pose_Model`\n","- **Description**: A model that processes pose landmarks to output a feature vector.\n","- **Methods**:\n","  - `forward(pose_landmarks)`: Forward pass through the Pose model."]},{"cell_type":"code","execution_count":79,"metadata":{"executionInfo":{"elapsed":631,"status":"ok","timestamp":1734093105063,"user":{"displayName":"ai research","userId":"07349987832510586956"},"user_tz":-120},"id":"fjTdgCRKCjfX"},"outputs":[],"source":["# class ResidualBlock(nn.Module):\n","#     \"\"\"\n","#     A residual block for 1D convolutional layers.\n","#     \"\"\"\n","#     def __init__(self, in_channels, out_channels, stride=1):\n","#         super(ResidualBlock, self).__init__()\n","#         self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n","#         self.bn1 = nn.BatchNorm1d(out_channels)\n","#         self.relu = nn.ReLU()\n","#         self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n","#         self.bn2 = nn.BatchNorm1d(out_channels)\n","\n","#         # Shortcut connection\n","#         self.shortcut = nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=stride)\n","#         self.shortcut_bn = nn.BatchNorm1d(out_channels)\n","\n","#     def forward(self, x):\n","#         shortcut = self.shortcut(x)\n","#         shortcut = self.shortcut_bn(shortcut)\n","\n","#         x = self.conv1(x)\n","#         x = self.bn1(x)\n","#         x = self.relu(x)\n","#         x = self.conv2(x)\n","#         x = self.bn2(x)\n","\n","#         x += shortcut\n","#         x = self.relu(x)\n","#         return x\n","\n","class Pose_Model(nn.Module):\n","    \"\"\"\n","    Pose_Model is a PyTorch neural network module designed to process pose landmarks\n","    and output a feature vector for further analysis.\n","    \"\"\"\n","\n","    def __init__(self, input_size=528, hidden_size1=512, hidden_size2=1024, hidden_size3=2048, final_size=2048):\n","        super(Pose_Model, self).__init__()\n","\n","        # Define the neural network layers\n","        self.fc1 = nn.Linear(input_size, hidden_size1)    # First hidden layer with reduced size\n","        self.bn1 = nn.BatchNorm1d(hidden_size1)           # Batch Normalization\n","        self.relu1 = nn.ReLU()\n","\n","        self.fc2 = nn.Linear(hidden_size1, hidden_size2)  # Second hidden layer with increased size\n","        self.bn2 = nn.BatchNorm1d(hidden_size2)           # Batch Normalization\n","        self.relu2 = nn.ReLU()\n","\n","        self.fc3 = nn.Linear(hidden_size2, hidden_size3)  # Third hidden layer with increased size\n","        self.bn3 = nn.BatchNorm1d(hidden_size3)           # Batch Normalization\n","        self.relu3 = nn.ReLU()\n","\n","        self.fc4 = nn.Linear(hidden_size3, final_size)    # Output layer\n","        self.relu4 = nn.ReLU()\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Forward pass through the Pose Model.\n","\n","        pose_landmarks: Tensor of shape [batch_size, num_frames, 528]\n","        \"\"\"\n","        try:\n","            batch_size, num_frames, _ = x.shape     # batch_size, num_frames, 528\n","\n","            # Process all frames at once\n","            x = self.fc1(x.view(-1, x.size(-1)))  # Shape: [batch_size*num_frames, hidden_size1]\n","            x = self.bn1(x)  # Batch Normalization\n","            x = self.relu1(x)\n","\n","            x = self.fc2(x)\n","            x = self.bn2(x)  # Batch Normalization\n","            x = self.relu2(x)\n","\n","            x = self.fc3(x)\n","            x = self.bn3(x)  # Batch Normalization\n","            x = self.relu3(x)\n","\n","            x = self.fc4(x)  # Final layer\n","            x = self.relu4(x)\n","\n","            # Reshape back to [batch_size, num_frames, final_size]\n","            frame_features = x.view(batch_size, num_frames, -1)  # Shape: [batch_size, num_frames, final_size]\n","\n","            # Aggregate the frame features (mean pooling)\n","            pooled_features = frame_features.mean(dim=1)  # Shape: [batch_size, final_size]\n","\n","            # print(\"pooled_features shape:\", pooled_features.shape)\n","\n","        except Exception as e:\n","            print(\"An error occurred in Pose_Model:\")\n","            print(f\"Error: {e}\")\n","        return pooled_features  # Shape: [batch_size, final_size]"]},{"cell_type":"markdown","metadata":{"id":"1Y8h4fUACDZm"},"source":["## `Dual_Combined_Model`\n","\n","- **Description**: Combines two instances of `Combined_Video_Pose_Model` to produce classification and rating outputs.\n","\n","- **Methods**:\n","  - `forward(pixel_values_1, bool_masked_pos_1, pose_landmarks_tensor_1, pixel_values_2, bool_masked_pos_2, pose_landmarks_tensor_2)`: Forward pass through the dual model.\n"]},{"cell_type":"code","execution_count":78,"metadata":{"executionInfo":{"elapsed":439,"status":"ok","timestamp":1734093099326,"user":{"displayName":"ai research","userId":"07349987832510586956"},"user_tz":-120},"id":"2HufVACb4BVN"},"outputs":[],"source":["class Dual_Combined_Model(nn.Module):\n","    \"\"\"\n","    Dual_Combined_Model combines two instances of Combined_Video_Pose_Model\n","    to produce classification and rating outputs.\n","    \"\"\"\n","\n","    def __init__(self, input_size=4096, hidden_size=512):\n","        super(Dual_Combined_Model, self).__init__()\n","\n","        # Initialize two instances of Combined_Video_Pose_Model\n","        self.front_model = Pose_Model()\n","        self.lat_model = Pose_Model()\n","\n","        # Fully connected layers for classification\n","        self.classification_layer = nn.Linear(input_size, hidden_size)  # Initial layer after concatenation\n","        self.classification_relu = nn.ReLU()\n","        self.classification_dropout = nn.Dropout(0.5)\n","\n","        self.classification_output = nn.Linear(hidden_size, 3)  # Output layer for 3 classes\n","\n","    def forward(self, lat_pose, front_pose):\n","        \"\"\"\n","        Forward pass for combining lateral and frontal pose inputs.\n","\n","        Args:\n","            lat_pose: Tensor of shape [batch_size, num_frames, input_size] for lateral poses.\n","            front_pose: Tensor of shape [batch_size, num_frames, input_size] for frontal poses.\n","\n","        Returns:\n","            classification_output: Tensor of shape [batch_size, 3].\n","            combined_hidden: Tensor of shape [batch_size, 4096].\n","        \"\"\"\n","        # Process lateral and frontal poses independently\n","        lat_hidden = self.lat_model(lat_pose)  # Shape: [batch_size, 2048]\n","        front_hidden = self.front_model(front_pose)  # Shape: [batch_size, 2048]\n","\n","        if lat_hidden is None or front_hidden is None:\n","            raise ValueError(\"One of the models returned None.\")\n","\n","        # Concatenate the features from both models\n","        combined_hidden = torch.cat((lat_hidden, front_hidden), dim=1)  # Shape: [batch_size, 4096]\n","        # print(\"combined_hidden shape\", combined_hidden.shape)\n","        # Classification path\n","        classification_hidden = self.classification_layer(combined_hidden)\n","        classification_hidden = self.classification_relu(classification_hidden)\n","        classification_hidden = self.classification_dropout(classification_hidden)\n","        classification_output = self.classification_output(classification_hidden)\n","\n","        return classification_output, combined_hidden\n"]},{"cell_type":"markdown","metadata":{"id":"VHyY8adi9rN6"},"source":["## `CriteriaPredictionModel`\n","\n","- **Description**: A deep neural network for predicting multiple binary ratings (yes/no) using a series of fully connected layers, ReLU activations, and dropout for regularization. The model outputs a probability for each rating.\n","\n","- **Methods**:\n","  - `forward(x)`: Forward pass through the network. The input is passed through five fully connected layers, each with ReLU and dropout, and the final output is processed by a sigmoid activation to produce binary classification probabilities.\n"]},{"cell_type":"code","execution_count":85,"metadata":{"executionInfo":{"elapsed":473,"status":"ok","timestamp":1734096533778,"user":{"displayName":"ai research","userId":"07349987832510586956"},"user_tz":-120},"id":"rQAWzMLI5U_E"},"outputs":[],"source":["class CriteriaPredictionModel(nn.Module):\n","    \"\"\"\n","    RatingPredictionModel predicts multiple yes/no ratings with a deeper network architecture.\n","    The model uses binary classification for each output rating (5 in total).\n","    \"\"\"\n","    def __init__(self, input_size=4096, hidden_size1=2048, hidden_size2=1024, hidden_size3=512, hidden_size4=256, hidden_size5=128,\n","                 output_size=5, dropout_rate=0.5):\n","        super(CriteriaPredictionModel, self).__init__()\n","\n","        # First fully connected layer\n","        self.fc1 = nn.Linear(input_size, hidden_size1)\n","        self.relu1 = nn.ReLU()\n","        self.dropout1 = nn.Dropout(dropout_rate)\n","\n","        # Second fully connected layer\n","        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n","        self.relu2 = nn.ReLU()\n","        self.dropout2 = nn.Dropout(dropout_rate)\n","\n","        # Adding more depth\n","        self.fc3 = nn.Linear(hidden_size2, hidden_size3)\n","        self.relu3 = nn.ReLU()\n","        self.dropout3 = nn.Dropout(dropout_rate)\n","\n","        self.fc4 = nn.Linear(hidden_size3, hidden_size4)\n","        self.relu4 = nn.ReLU()\n","        self.dropout4 = nn.Dropout(dropout_rate)\n","\n","        self.fc5 = nn.Linear(hidden_size4, hidden_size5)\n","        self.relu5 = nn.ReLU()\n","        self.dropout5 = nn.Dropout(dropout_rate)\n","\n","        # Output layer for binary classification (yes/no for each of the 5 ratings)\n","        self.output_layer = nn.Linear(hidden_size5, output_size)\n","        self.sigmoid = nn.Sigmoid()  # Sigmoid for binary yes/no predictions\n","\n","    def forward(self, x):\n","        # Forward pass through the network with multiple layers\n","        x = self.fc1(x)\n","        x = self.relu1(x)\n","        x = self.dropout1(x)\n","\n","        x = self.fc2(x)\n","        x = self.relu2(x)\n","        x = self.dropout2(x)\n","\n","        x = self.fc3(x)\n","        x = self.relu3(x)\n","        x = self.dropout3(x)\n","\n","        x = self.fc4(x)\n","        x = self.relu4(x)\n","        x = self.dropout4(x)\n","\n","        x = self.fc5(x)\n","        x = self.relu5(x)\n","        x = self.dropout5(x)\n","\n","        # Final binary classification\n","        ratings = self.output_layer(x)\n","        return self.sigmoid(ratings)  # Returns output_size values, each in range [0, 1] for yes/no classification\n"]},{"cell_type":"markdown","metadata":{"id":"PytDrrlz9xq7"},"source":["## `DeepClassificationWithRatingModel`\n","\n","- **Description**: The `DeepClassificationWithRatingModel` integrates the `DeepDualCombinedModel` and adds a separate rating prediction model. If the classification output predicts class `0`, the rating model is triggered. It uses different criteria models for deadlift, squat, and lunges based on the predicted class.\n","\n","- **Methods**:\n","  - `forward(combined_hidden, predicted_class)`:\n","    - Takes the `combined_hidden` state and the `predicted_class`.\n","    - If class `0` is predicted, the `dead_criteria_model` is used to predict ratings.\n","    - If class `1` is predicted, the `squat_criteria_model` is used.\n","    - If class `2` is predicted, the `lunges_criteria_model` is used.\n","    - Returns the predicted ratings based on the class.\n"]},{"cell_type":"code","execution_count":86,"metadata":{"executionInfo":{"elapsed":492,"status":"ok","timestamp":1734096537635,"user":{"displayName":"ai research","userId":"07349987832510586956"},"user_tz":-120},"id":"xisbxmLc5U_E"},"outputs":[],"source":["class DeepClassificationWithRatingModel(nn.Module):\n","    \"\"\"\n","    DeepClassificationWithRatingModel integrates the DeepDualCombinedModel and\n","    adds a separate rating prediction model. If the classification output predicts class `0`,\n","    the rating model is triggered.\n","    \"\"\"\n","    def __init__(self):\n","        super(DeepClassificationWithRatingModel, self).__init__()\n","\n","        # Rating model with more layers\n","        self.dead_criteria_model = CriteriaPredictionModel(output_size=5)\n","        self.lunges_criteria_model = CriteriaPredictionModel(output_size=7)\n","        self.squat_criteria_model = CriteriaPredictionModel(output_size=6)\n","\n","    def forward(self,combined_hidden,predicted_class):\n","        try:\n","            # Initialize ratings as None\n","            ratings = None\n","\n","            # If class `0` is predicted, trigger rating prediction\n","            if predicted_class == 0:\n","                ratings = self.dead_criteria_model(combined_hidden)\n","            elif predicted_class == 1:\n","                ratings = self.squat_criteria_model(combined_hidden)\n","            elif predicted_class == 2:\n","                ratings = self.lunges_criteria_model(combined_hidden)\n","            return ratings\n","\n","        except Exception as e:\n","            print(f\"Error during forward pass in DeepClassificationWithRatingModel: {e}\")\n","            raise"]},{"cell_type":"markdown","metadata":{"id":"KmiORcTVCe8E"},"source":["## `PoseVideoDataset`\n","\n","- **Description**: A custom PyTorch Dataset designed to load video frames and pose landmarks, along with action class labels and ratings. It supports deadlift, squat, and lunge actions with different rating models for each. The dataset processes video frames, extracts pose landmarks, and normalizes ratings based on action class.\n","\n","- **Methods**:\n","  - `__len__()`: Returns the number of samples in the dataset.\n","  - `__getitem__(idx)`: Loads and processes the data at the specified index:\n","    - Loads video frames for both frontal and lateral views.\n","    - Processes and normalizes video frames using the processor.\n","    - Extracts pose landmarks and action class labels.\n","    - Retrieves and normalizes ratings based on action class (Deadlift, Squat, or Lunge).\n","  - `_process_ratings(df)`: Processes and normalizes the ratings data from the corresponding DataFrame:\n","    - Extracts relevant columns (ending in 'F' or 'L').\n","    - Normalizes the scores and applies a threshold (0 or 1 based on the condition).\n","    - Returns the mean of the scores for each rating.\n"]},{"cell_type":"code","execution_count":87,"metadata":{"executionInfo":{"elapsed":465,"status":"ok","timestamp":1734096540578,"user":{"displayName":"ai research","userId":"07349987832510586956"},"user_tz":-120},"id":"6gXntBrL3qj3"},"outputs":[],"source":["def compute_pairwise_distances(points_tensor):\n","    \"\"\"\n","    Compute pairwise distances between 33 pose landmarks for each frame.\n","\n","    Args:\n","        points_tensor (torch.Tensor): Tensor of shape [num_frames, 33, 3],\n","                                       where each row is a point (x, y, z) for each frame.\n","\n","    Returns:\n","        torch.Tensor: Tensor of shape [num_frames, 528], containing pairwise distances for each frame.\n","    \"\"\"\n","    num_frames, num_points, _ = points_tensor.size()\n","    distances = []\n","\n","    # Iterate over frames\n","    for frame_idx in range(num_frames):\n","        frame_points = points_tensor[frame_idx]  # Shape: [33, 3]\n","        frame_distances = []\n","\n","        # Iterate over unique pairs of points\n","        for i in range(num_points):\n","            for j in range(i + 1, num_points):  # Ensure each pair is only computed once\n","                point1 = frame_points[i]\n","                point2 = frame_points[j]\n","\n","                # Compute Euclidean distance\n","                dist = torch.sqrt(torch.sum((point1 - point2) ** 2))\n","                frame_distances.append(dist)\n","\n","        # Append distances for the current frame\n","        distances.append(torch.stack(frame_distances))  # Shape: [528]\n","\n","    # Stack distances for all frames\n","    return torch.stack(distances)  # Shape: [num_frames, 528]"]},{"cell_type":"code","execution_count":88,"metadata":{"executionInfo":{"elapsed":480,"status":"ok","timestamp":1734096542894,"user":{"displayName":"ai research","userId":"07349987832510586956"},"user_tz":-120},"id":"gzjcU07Q9FLq"},"outputs":[],"source":["class PoseVideoDataset(Dataset):\n","\n","    def __init__(self, df, num_frames):\n","        self.df = df\n","        self.num_frames = num_frames\n","        self.train_df_dead = train_df_dead\n","        self.train_df_squat = train_df_squat\n","        self.train_df_lunge = train_df_lunge\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        row = self.df.iloc[idx]\n","\n","        # Get frontal and lateral video paths and index\n","        num_video_frontal = row['Num Video Frontal']\n","        num_video_lateral = row['Num Video Lateral']\n","        num_idx = row['NumIdx']\n","        action = row['Action']\n","\n","        # Extract pose landmarks from video frames\n","        pose_landmarks_frontal = row['front_pose']\n","        pose_landmarks_lateral = row['lat_pose']\n","        pose_landmarks_tensor_frontal = torch.tensor(pose_landmarks_frontal).float()\n","        pose_landmarks_tensor_lateral = torch.tensor(pose_landmarks_lateral).float()\n","        distances_frontal = compute_pairwise_distances(pose_landmarks_tensor_frontal)\n","        distances_lateral = compute_pairwise_distances(pose_landmarks_tensor_lateral)\n","\n","        # print(f\"pose_landmarks shape: {pose_landmarks_tensor_frontal.shape}\")\n","        # print(f\"distances_frontal shape: {distances_frontal.shape}\")\n","\n","        # pose_landmarks_tensor_frontal = torch.cat((pose_landmarks_tensor_frontal, distances_frontal), dim=0)\n","        # pose_landmarks_tensor_lateral = torch.cat((pose_landmarks_tensor_lateral, distances_lateral), dim=0)\n","\n","        # Get labels (action class)\n","        label_class = torch.tensor(row['class'], dtype=torch.long)\n","\n","        # Initialize ratings\n","        ratings = None\n","\n","        # Check label_class and load appropriate DataFrame\n","        if label_class.item() == 0:  # Deadlift\n","            ratings = self._process_ratings(self.train_df_dead,row)\n","        elif label_class.item() == 1:  # Squat\n","            ratings = self._process_ratings(self.train_df_squat,row)\n","        elif label_class.item() == 2:  # Lunge\n","            ratings = self._process_ratings(self.train_df_lunge,row)\n","\n","        # Convert ratings to tensor\n","        ratings = torch.tensor(ratings, dtype=torch.float32) if ratings is not None else None\n","\n","        return (distances_frontal, distances_lateral, label_class, ratings)\n","\n","    def _process_ratings(self, df,row):\n","        \"\"\"\n","        Process the ratings DataFrame to extract and normalize scores.\n","\n","        Args:\n","            df (pd.DataFrame): DataFrame containing ratings for the specific action.\n","\n","        Returns:\n","            list: Normalized and thresholded scores.\n","        \"\"\"\n","        # Select columns ending with 'F' or 'L'\n","        relevant_columns = [col for col in df.columns if col.endswith('F') or col.endswith('L')]\n","\n","        # Extract ratings and normalize\n","        scores = row[relevant_columns].values\n","\n","\n","        # Apply threshold: Convert to 0 or 1 based on specific thresholding conditions\n","        thresholded_scores = np.where(scores \u003e= 0.5, 1, 0)\n","\n","        return thresholded_scores.tolist()  # Return mean of the scores for each sample"]},{"cell_type":"code","execution_count":89,"metadata":{"executionInfo":{"elapsed":493,"status":"ok","timestamp":1734096552349,"user":{"displayName":"ai research","userId":"07349987832510586956"},"user_tz":-120},"id":"CBl_FBpQBa1e"},"outputs":[],"source":["def create_dataloader(df, num_frames, batch_size=16, shuffle=True):\n","    \"\"\"\n","    Creates a PyTorch DataLoader from the PoseVideoDataset.\n","\n","    Args:\n","        df (pd.DataFrame): DataFrame containing the dataset information.\n","        num_frames (int): The number of frames to extract from each video.\n","        batch_size (int, optional): Batch size for the DataLoader. Defaults to 8.\n","        shuffle (bool, optional): Whether to shuffle the data. Defaults to True.\n","\n","    Returns:\n","        DataLoader: A PyTorch DataLoader for the dataset.\n","    \"\"\"\n","    dataset = PoseVideoDataset(df, num_frames)\n","    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n"]},{"cell_type":"markdown","metadata":{"id":"NvW6aZGJ-QGS"},"source":["## `train_combined_model`\n","\n","- **Description**: This function trains both the classification model (`Dual_Combined_Model`) and the rating prediction model (`CriteriaPredictionModel`). It evaluates them after each epoch and saves the best-performing models based on validation loss. It also includes early stopping if no improvement is observed for a set number of epochs.\n","\n","- **Args**:\n","  - `model (torch.nn.Module)`: The classification model (e.g., `Dual_Combined_Model`).\n","  - `criteria_model (torch.nn.Module)`: The rating prediction model (e.g., `CriteriaPredictionModel`).\n","  - `train_dataloader (DataLoader)`: A DataLoader providing the training data.\n","  - `eval_dataloader (DataLoader)`: A DataLoader providing the evaluation data.\n","  - `epochs (int, optional)`: Number of epochs to train. Defaults to 1000.\n","  - `lr (float, optional)`: Learning rate for the optimizer. Defaults to 1e-4.\n","  - `device (str, optional)`: The device to train the model on ('cpu' or 'cuda'). Defaults to 'cpu'.\n","  - `clip_grad_norm (float, optional)`: Maximum norm for gradient clipping. Defaults to 1.0.\n","  - `patience (int, optional)`: Number of epochs with no improvement after which training will be stopped. Defaults to 5.\n","\n","- **Returns**:\n","  - None: The function prints the training progress, validation loss, classification accuracy, and rating accuracy during training.\n","\n","- **Steps**:\n","  1. **Model Initialization**: Moves both the classification and rating models to the specified device.\n","  2. **Optimizer Setup**: Uses the Adam optimizer for both models with the specified learning rate.\n","  3. **Loss Functions**: Defines loss functions for both classification (`CrossEntropyLoss`) and ratings (`BCEWithLogitsLoss`).\n","  4. **Training Loop**:\n","     - Performs a forward pass through the classification model and computes the classification loss.\n","     - Computes the rating prediction loss only if the predicted class matches the actual class.\n","     - Combines both the classification and rating losses and performs backpropagation.\n","  5. **Gradient Clipping**: Clips gradients to avoid exploding gradients during backpropagation.\n","  6. **Model Evaluation**: Evaluates the models after each epoch and prints the results.\n","  7. **Early Stopping**: Monitors validation loss and triggers early stopping if no improvement is observed for a specified number of epochs.\n","  8. **Model Checkpointing**: Saves the best-performing models based on validation loss.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PSZbVvGz-Itz"},"outputs":[],"source":["from torch.utils.tensorboard import SummaryWriter\n","\n","def train_combined_model(Dual_Combined_Model, criteria_model, train_dataloader, eval_dataloader, epochs=1000, lr=1e-4,\n","                         device='cpu', clip_grad_norm=1.0, patience=7):\n","\n","    # TensorBoard setup\n","    writer = SummaryWriter(log_dir=LOG_DIR)\n","\n","    Dual_Combined_Model.to(device)\n","    criteria_model.to(device)\n","\n","    # Set up optimizer and loss functions\n","    optimizer = optim.Adam(list(Dual_Combined_Model.parameters()) + list(criteria_model.parameters()), lr=lr)\n","    activity_loss = nn.CrossEntropyLoss()  # Loss for classification task\n","    feature_loss = nn.BCEWithLogitsLoss()  # Loss for rating task (binary)\n","\n","    # Learning rate scheduler\n","    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.5)\n","\n","    best_eval_loss = float('inf')\n","    patience_counter = 0\n","\n","    for epoch in range(epochs):\n","        Dual_Combined_Model.train()\n","        criteria_model.train()\n","        running_loss = 0.0\n","\n","        for batch_idx, batch in enumerate(train_dataloader):\n","            # Calculate progress percentage\n","            progress = (batch_idx + 1) / len(train_dataloader) * 100\n","\n","            # Unpack batch data and move to the specified device\n","            (pose_landmarks_tensor_frontal, pose_landmarks_tensor_lateral,\n","             label_class, ratings) = [tensor.to(device) for tensor in batch]\n","\n","            optimizer.zero_grad()\n","\n","            # Forward pass through the classification model\n","            classification_output, combined_hidden = Dual_Combined_Model(pose_landmarks_tensor_frontal, pose_landmarks_tensor_lateral)\n","            _, predicted_class = torch.max(classification_output, 1)\n","\n","            # Loss for classification\n","            loss_class = activity_loss(classification_output, label_class)\n","\n","            # Forward pass through the rating prediction model\n","            for i in range(label_class.size(0)):\n","                actual_class = label_class[i].item()\n","                predicted_class_item = predicted_class[i].item()\n","\n","                if predicted_class_item == actual_class:\n","                    if actual_class == 0:  # Deadlift\n","                        ratings_output = criteria_model.dead_criteria_model(combined_hidden[i])\n","                    elif actual_class == 1:  # Squat\n","                        ratings_output = criteria_model.squat_criteria_model(combined_hidden[i])\n","                    elif actual_class == 2:  # Lunges\n","                        ratings_output = criteria_model.lunges_criteria_model(combined_hidden[i])\n","                    loss_ratings = feature_loss(ratings_output, ratings[i].float())\n","                else:\n","                    loss_ratings = torch.tensor(2.0, device=device, requires_grad=True)  # High loss if mismatched\n","\n","                # Combine classification and rating losses\n","                loss = loss_class + loss_ratings\n","\n","                # Backward pass and optimization\n","                loss.backward()\n","                torch.nn.utils.clip_grad_norm_(list(Dual_Combined_Model.parameters()) + list(criteria_model.parameters()), clip_grad_norm)\n","                optimizer.step()\n","\n","                running_loss += loss.item()\n","\n","                # Print progress during each epoch\n","                print(f\"Epoch [{epoch + 1}/{epochs}], Progress: {progress:.2f}%, Batch [{batch_idx + 1}/{len(train_dataloader)}], Loss: {loss.item():.4f}\")\n","\n","        avg_loss = running_loss / len(train_dataloader)\n","\n","        # Log training loss to TensorBoard\n","        writer.add_scalar(\"Loss/Train\", avg_loss, epoch)\n","\n","        # Evaluate both models after each epoch\n","        eval_loss, eval_accuracy, eval_rating_accuracy = evaluate_combined_model(\n","            Dual_Combined_Model, criteria_model, eval_dataloader, activity_loss, feature_loss, device\n","        )\n","\n","        # Log validation metrics to TensorBoard\n","        writer.add_scalar(\"Loss/Validation\", eval_loss, epoch)\n","        writer.add_scalar(\"Accuracy/Classification\", eval_accuracy, epoch)\n","        writer.add_scalars(\"Rating Accuracy\", {\n","            \"Deadlift\": eval_rating_accuracy['deadlift'],\n","            \"Squat\": eval_rating_accuracy['squat'],\n","            \"Lunges\": eval_rating_accuracy['lunges']\n","        }, epoch)\n","\n","        # Print summary for each epoch\n","        print(f\"Epoch [{epoch + 1}/{epochs}] Summary: \"\n","              f\"Train Loss: {avg_loss:.4f}, Eval Loss: {eval_loss:.4f}, \"\n","              f\"Accuracy: {eval_accuracy:.4f}\")\n","\n","        # Scheduler step\n","        scheduler.step(eval_loss)\n","\n","        # Early stopping and model saving\n","        if eval_loss \u003c best_eval_loss:\n","            best_eval_loss = eval_loss\n","            patience_counter = 0\n","            torch.save(Dual_Combined_Model.state_dict(), f\"best_combined_model_epoch_{epoch + 1}.pt\")\n","            torch.save(criteria_model.state_dict(), f\"best_rating_model_epoch_{epoch + 1}.pt\")\n","            print(\"Model checkpoint saved.\")\n","        else:\n","            patience_counter += 1\n","            if patience_counter \u003e= patience:\n","                print(\"Early stopping triggered.\")\n","                break\n","\n","    writer.close()  # Close TensorBoard writer\n","    print(\"Training complete.\")\n"]},{"cell_type":"markdown","metadata":{"id":"-dusNp1b-Z1k"},"source":["## `evaluate_combined_model`\n","\n","- **Description**: This function evaluates both the classification and rating prediction models on the provided dataset. It computes the average evaluation loss, classification accuracy, and rating accuracies for different actions (deadlift, squat, lunges) using a given `DataLoader` and loss functions.\n","\n","- **Args**:\n","  - `classification_model (torch.nn.Module)`: The classification model (e.g., `Dual_Combined_Model`).\n","  - `criteria_model (torch.nn.Module)`: The rating prediction model (e.g., `CriteriaPredictionModel`).\n","  - `dataloader (DataLoader)`: A DataLoader providing the evaluation data.\n","  - `criterion_class (nn.Module)`: The loss function for the classification task.\n","  - `criterion_ratings (nn.Module)`: The loss function for the rating task.\n","  - `device (str)`: The device to perform evaluation on ('cpu' or 'cuda').\n","\n","- **Returns**:\n","  - `float`: The average evaluation loss across the dataset.\n","  - `dict`: A dictionary containing the classification accuracy and rating accuracies for each action (deadlift, squat, lunges).\n","\n","- **Steps**:\n","  1. **Set Evaluation Mode**: Sets the models (`classification_model` and `criteria_model`) to evaluation mode.\n","  2. **Initialize Metrics**: Initializes accumulators for loss, classification accuracy, and rating accuracy for each action.\n","  3. **Evaluation Loop**:\n","     - Performs a forward pass through the classification model to get predictions and computes classification loss.\n","     - For each sample in the batch, if the predicted class matches the actual class, it computes the rating accuracy for that action.\n","     - The rating predictions are compared with the ground truth ratings, and accuracy is calculated for each action (deadlift, squat, lunges).\n","  4. **Compute Average Metrics**: Computes the average classification loss, overall classification accuracy, and rating accuracy for each action.\n","  5. **Return Results**: Returns the average loss, classification accuracy, and rating accuracies.\n"]},{"cell_type":"code","execution_count":91,"metadata":{"executionInfo":{"elapsed":452,"status":"ok","timestamp":1734096568553,"user":{"displayName":"ai research","userId":"07349987832510586956"},"user_tz":-120},"id":"hqEEcG285U_E"},"outputs":[],"source":["def evaluate_combined_model(classification_model, criteria_model, dataloader, criterion_class, criterion_ratings, device):\n","    \"\"\"\n","    Evaluates both the classification and rating models on the provided dataset.\n","\n","    Args:\n","        classification_model (torch.nn.Module): The classification model.\n","        criteria_model (torch.nn.Module): The rating prediction model.\n","        dataloader (DataLoader): A DataLoader providing the evaluation data.\n","        criterion_class (nn.Module): The loss function for classification.\n","        criterion_ratings (nn.Module): The loss function for ratings.\n","        device (str): The device to perform evaluation on ('cpu' or 'cuda').\n","\n","    Returns:\n","        float: Average evaluation loss.\n","        dict: Classification accuracy and rating accuracies for each action (deadlift, squat, lunges).\n","    \"\"\"\n","    classification_model.eval()\n","    criteria_model.eval()\n","    total_loss = 0.0\n","    correct_predictions_class = 0\n","    total_samples_class = 0\n","\n","    # Initialize accumulators for rating accuracy per feature\n","    rating_accumulators = {'deadlift': 0, 'squat': 0, 'lunges': 0}\n","    total_rating_samples = {'deadlift': 0, 'squat': 0, 'lunges': 0}\n","\n","    a =0\n","    with torch.no_grad():\n","        for batch in dataloader:\n","            (pose_landmarks_tensor_frontal,pose_landmarks_tensor_lateral,\n","             label_class, ratings) = [tensor.to(device) for tensor in batch]\n","\n","            # Forward pass through the classification model\n","            classification_output, combined_hidden = classification_model(pose_landmarks_tensor_frontal, pose_landmarks_tensor_lateral)\n","            _, predicted_class = torch.max(classification_output, 1)\n","\n","            # Classification loss and accuracy\n","            loss_class = criterion_class(classification_output, label_class)\n","            total_loss += loss_class.item()\n","            correct_predictions_class += (predicted_class == label_class).sum().item()\n","            total_samples_class += label_class.size(0)\n","\n","            # Rating accuracy calculation per feature (only if predicted class matches actual class)\n","            for i in range(label_class.size(0)):  # Loop over each sample in the batch\n","                actual_class = label_class[i].item()\n","                predicted_class_item = predicted_class[i].item()\n","\n","                if actual_class == predicted_class_item:\n","                    if actual_class == 0:  # Deadlift\n","                        ratings_output = criteria_model.dead_criteria_model(combined_hidden[i])\n","                        predicted_ratings = torch.sigmoid(ratings_output) \u003e 0.5\n","                        correct_ratings = (predicted_ratings == ratings[i].byte()).sum().item()\n","                        rating_accumulators['deadlift'] += correct_ratings\n","                        total_rating_samples['deadlift'] += ratings[i].numel()\n","                        print(f\"Predicted : {predicted_ratings}\")\n","                        print(f\"actual : {ratings[i].byte()}\")\n","                        print(correct_ratings)\n","                        print(f\"rating_accumulators : {rating_accumulators['deadlift']}\")\n","                        print(f\"total_rating_samples : {total_rating_samples['deadlift']}\")\n","                    elif actual_class == 1:  # Squat\n","                        ratings_output = criteria_model.squat_criteria_model(combined_hidden[i])\n","                        predicted_ratings = torch.sigmoid(ratings_output) \u003e 0.5\n","                        correct_ratings = (predicted_ratings == ratings[i].byte()).sum().item()\n","                        rating_accumulators['squat'] += correct_ratings\n","                        total_rating_samples['squat'] += ratings[i].numel()\n","                        print(f\"Predicted : {predicted_ratings}\")\n","                        print(f\"actual : {ratings[i].byte()}\")\n","                        print(f\"correct_ratings : {correct_ratings}\")\n","                        print(f\"rating_accumulators : {rating_accumulators['squat']}\")\n","                        print(f\"total_rating_samples : {total_rating_samples['squat']}\")\n","                    elif actual_class == 2:  # Lunges\n","                        ratings_output = criteria_model.lunges_criteria_model(combined_hidden[i])\n","                        predicted_ratings = torch.sigmoid(ratings_output) \u003e 0.5\n","                        correct_ratings = (predicted_ratings == ratings[i].byte()).sum().item()\n","                        rating_accumulators['lunges'] += correct_ratings\n","                        total_rating_samples['lunges'] += ratings[i].numel()\n","                        print(f\"Predicted : {predicted_ratings}\")\n","                        print(f\"actual : {ratings[i].byte()}\")\n","                        print(correct_ratings)\n","                        print(f\"rating_accumulators : {rating_accumulators['lunges']}\")\n","                        print(f\"total_rating_samples : {total_rating_samples['lunges']}\")\n","\n","\n","            print(f\"{a} , {len(dataloader)}\")\n","            a=a=1\n","\n","    # Calculate the average loss and classification accuracy\n","    avg_loss = total_loss / len(dataloader)\n","    accuracy_class = correct_predictions_class / total_samples_class if total_samples_class \u003e 0 else 0.0\n","    # Calculate rating accuracy for each action\n","    rating_accuracy = {\n","        'deadlift': rating_accumulators['deadlift'] / total_rating_samples['deadlift'] if total_rating_samples['deadlift'] \u003e 0 else 0.0,\n","        'squat': rating_accumulators['squat'] / total_rating_samples['squat'] if total_rating_samples['squat'] \u003e 0 else 0.0,\n","        'lunges': rating_accumulators['lunges'] / total_rating_samples['lunges'] if total_rating_samples['lunges'] \u003e 0 else 0.0\n","    }\n","\n","    return avg_loss, accuracy_class, rating_accuracy\n"]},{"cell_type":"code","execution_count":92,"metadata":{"executionInfo":{"elapsed":484,"status":"ok","timestamp":1734096574856,"user":{"displayName":"ai research","userId":"07349987832510586956"},"user_tz":-120},"id":"p7ro9pEnuXbR"},"outputs":[],"source":["dataloader = create_dataloader(train_df, 16, batch_size=1)\n","eval_dataloader = create_dataloader(val_df, 16, batch_size=1)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":93,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":491,"status":"ok","timestamp":1734096576819,"user":{"displayName":"ai research","userId":"07349987832510586956"},"user_tz":-120},"id":"2t9ubI9OzsRs","outputId":"11d5dcd5-07f4-4daf-eb75-07de37f93da3"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([1, 16, 528])\n"]}],"source":["for data in dataloader:\n","    print(data[0].shape)\n","    break\n"]},{"cell_type":"code","execution_count":101,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":874},"executionInfo":{"elapsed":2197,"status":"ok","timestamp":1734097601271,"user":{"displayName":"ai research","userId":"07349987832510586956"},"user_tz":-120},"id":"9QUUzNksPXsF"},"outputs":[{"name":"stdout","output_type":"stream","text":["The tensorboard extension is already loaded. To reload it, use:\n","  %reload_ext tensorboard\n"]},{"data":{"application/javascript":["\n","        (async () =\u003e {\n","            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n","            url.searchParams.set('tensorboardColab', 'true');\n","            const iframe = document.createElement('iframe');\n","            iframe.src = url;\n","            iframe.setAttribute('width', '100%');\n","            iframe.setAttribute('height', '800');\n","            iframe.setAttribute('frameborder', 0);\n","            document.body.appendChild(iframe);\n","        })();\n","    "],"text/plain":["\u003cIPython.core.display.Javascript object\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["# Clear previous TensorBoard runs if needed\n","!rm -rf /content/drive/MyDrive/Vision_GYM_Research/tensorboard_logs\n","\n","# Start TensorBoard in Colab\n","%load_ext tensorboard\n","%tensorboard --logdir $LOG_DIR\n"]},{"cell_type":"code","execution_count":102,"metadata":{"executionInfo":{"elapsed":1881,"status":"ok","timestamp":1734097615656,"user":{"displayName":"ai research","userId":"07349987832510586956"},"user_tz":-120},"id":"STj984BCRYeo"},"outputs":[],"source":["%reload_ext tensorboard"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KyD6ki3yNfiH","outputId":"aa305e18-afa1-4dc6-ee2f-ef5c5f3d7893"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["# Initialize the model\n","dual_combined_model = Dual_Combined_Model()\n","rating_model = DeepClassificationWithRatingModel()\n","\n","print(device)\n","\n","# Train the model\n","train_combined_model(dual_combined_model, rating_model, dataloader, eval_dataloader, epochs=1000, lr=1e-4, device=device)"]},{"cell_type":"code","execution_count":84,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1860876,"status":"ok","timestamp":1734095656885,"user":{"displayName":"ai research","userId":"07349987832510586956"},"user_tz":-120},"id":"8eOrHYUp5U_F","outputId":"d4f9beef-27cf-4d1e-940e-f74702dd3843"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","Predicted : tensor([ True,  True,  True,  True,  True, False], device='cuda:0')\n","actual : tensor([1, 1, 1, 1, 1, 0], device='cuda:0', dtype=torch.uint8)\n","correct_ratings : 6\n","rating_accumulators : 35\n","total_rating_samples : 42\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([True, True, True, True, True, True, True], device='cuda:0')\n","actual : tensor([1, 1, 1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8)\n","7\n","rating_accumulators : 7\n","total_rating_samples : 7\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8)\n","4\n","rating_accumulators : 28\n","total_rating_samples : 40\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8)\n","4\n","rating_accumulators : 32\n","total_rating_samples : 45\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([True, True, True, True, True, True, True], device='cuda:0')\n","actual : tensor([1, 1, 1, 0, 1, 1, 0], device='cuda:0', dtype=torch.uint8)\n","5\n","rating_accumulators : 12\n","total_rating_samples : 14\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True,  True,  True, False], device='cuda:0')\n","actual : tensor([0, 1, 1, 1, 1, 0], device='cuda:0', dtype=torch.uint8)\n","correct_ratings : 5\n","rating_accumulators : 40\n","total_rating_samples : 48\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True,  True,  True, False], device='cuda:0')\n","actual : tensor([0, 0, 0, 0, 1, 0], device='cuda:0', dtype=torch.uint8)\n","correct_ratings : 2\n","rating_accumulators : 42\n","total_rating_samples : 54\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([True, True, True, True, True, True], device='cuda:0')\n","actual : tensor([1, 1, 1, 1, 1, 0], device='cuda:0', dtype=torch.uint8)\n","correct_ratings : 5\n","rating_accumulators : 47\n","total_rating_samples : 60\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 1, 0, 1], device='cuda:0', dtype=torch.uint8)\n","5\n","rating_accumulators : 37\n","total_rating_samples : 50\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([True, True, True, True, True, True], device='cuda:0')\n","actual : tensor([1, 0, 0, 0, 1, 0], device='cuda:0', dtype=torch.uint8)\n","correct_ratings : 2\n","rating_accumulators : 49\n","total_rating_samples : 66\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True,  True,  True, False], device='cuda:0')\n","actual : tensor([0, 0, 1, 0, 1, 1], device='cuda:0', dtype=torch.uint8)\n","correct_ratings : 2\n","rating_accumulators : 51\n","total_rating_samples : 72\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([True, True, True, True, True, True, True], device='cuda:0')\n","actual : tensor([1, 0, 1, 1, 1, 1, 0], device='cuda:0', dtype=torch.uint8)\n","5\n","rating_accumulators : 17\n","total_rating_samples : 21\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([True, True, True, True, True, True, True], device='cuda:0')\n","actual : tensor([0, 0, 1, 0, 1, 1, 0], device='cuda:0', dtype=torch.uint8)\n","3\n","rating_accumulators : 20\n","total_rating_samples : 28\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([True, True, True, True, True, True, True], device='cuda:0')\n","actual : tensor([1, 1, 1, 1, 1, 0, 1], device='cuda:0', dtype=torch.uint8)\n","6\n","rating_accumulators : 26\n","total_rating_samples : 35\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True,  True,  True, False], device='cuda:0')\n","actual : tensor([1, 1, 0, 1, 1, 0], device='cuda:0', dtype=torch.uint8)\n","correct_ratings : 5\n","rating_accumulators : 56\n","total_rating_samples : 78\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 0, 1, 1], device='cuda:0', dtype=torch.uint8)\n","3\n","rating_accumulators : 40\n","total_rating_samples : 55\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8)\n","4\n","rating_accumulators : 44\n","total_rating_samples : 60\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 0, 1, 1], device='cuda:0', dtype=torch.uint8)\n","3\n","rating_accumulators : 47\n","total_rating_samples : 65\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([True, True, True, True, True, True], device='cuda:0')\n","actual : tensor([1, 1, 1, 1, 1, 0], device='cuda:0', dtype=torch.uint8)\n","correct_ratings : 5\n","rating_accumulators : 61\n","total_rating_samples : 84\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True,  True,  True, False], device='cuda:0')\n","actual : tensor([0, 1, 1, 0, 1, 0], device='cuda:0', dtype=torch.uint8)\n","correct_ratings : 4\n","rating_accumulators : 65\n","total_rating_samples : 90\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True,  True,  True, False], device='cuda:0')\n","actual : tensor([1, 1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8)\n","correct_ratings : 5\n","rating_accumulators : 70\n","total_rating_samples : 96\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 1, 0, 1], device='cuda:0', dtype=torch.uint8)\n","5\n","rating_accumulators : 52\n","total_rating_samples : 70\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 0, 0, 1], device='cuda:0', dtype=torch.uint8)\n","4\n","rating_accumulators : 56\n","total_rating_samples : 75\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([True, True, True, True, True, True, True], device='cuda:0')\n","actual : tensor([1, 1, 1, 1, 1, 1, 0], device='cuda:0', dtype=torch.uint8)\n","6\n","rating_accumulators : 32\n","total_rating_samples : 42\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True,  True,  True, False], device='cuda:0')\n","actual : tensor([0, 1, 0, 1, 1, 0], device='cuda:0', dtype=torch.uint8)\n","correct_ratings : 4\n","rating_accumulators : 74\n","total_rating_samples : 102\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 1, 0, 1], device='cuda:0', dtype=torch.uint8)\n","5\n","rating_accumulators : 61\n","total_rating_samples : 80\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 0, 0, 1], device='cuda:0', dtype=torch.uint8)\n","4\n","rating_accumulators : 65\n","total_rating_samples : 85\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True,  True,  True, False], device='cuda:0')\n","actual : tensor([0, 1, 1, 1, 1, 0], device='cuda:0', dtype=torch.uint8)\n","correct_ratings : 5\n","rating_accumulators : 79\n","total_rating_samples : 108\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True,  True,  True, False], device='cuda:0')\n","actual : tensor([1, 1, 1, 1, 1, 0], device='cuda:0', dtype=torch.uint8)\n","correct_ratings : 6\n","rating_accumulators : 85\n","total_rating_samples : 114\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8)\n","4\n","rating_accumulators : 69\n","total_rating_samples : 90\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8)\n","4\n","rating_accumulators : 73\n","total_rating_samples : 95\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 1, 0, 1], device='cuda:0', dtype=torch.uint8)\n","5\n","rating_accumulators : 78\n","total_rating_samples : 100\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True,  True,  True, False], device='cuda:0')\n","actual : tensor([0, 1, 1, 1, 1, 0], device='cuda:0', dtype=torch.uint8)\n","correct_ratings : 5\n","rating_accumulators : 90\n","total_rating_samples : 120\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([True, True, True, True, True, True, True], device='cuda:0')\n","actual : tensor([0, 0, 1, 0, 1, 0, 0], device='cuda:0', dtype=torch.uint8)\n","2\n","rating_accumulators : 34\n","total_rating_samples : 49\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True,  True,  True, False], device='cuda:0')\n","actual : tensor([1, 1, 1, 0, 1, 1], device='cuda:0', dtype=torch.uint8)\n","correct_ratings : 4\n","rating_accumulators : 94\n","total_rating_samples : 126\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8)\n","4\n","rating_accumulators : 82\n","total_rating_samples : 105\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([0, 0, 1, 0, 1], device='cuda:0', dtype=torch.uint8)\n","3\n","rating_accumulators : 85\n","total_rating_samples : 110\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True,  True,  True, False], device='cuda:0')\n","actual : tensor([1, 1, 0, 1, 1, 0], device='cuda:0', dtype=torch.uint8)\n","correct_ratings : 5\n","rating_accumulators : 99\n","total_rating_samples : 132\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([True, True, True, True, True, True, True], device='cuda:0')\n","actual : tensor([1, 1, 1, 0, 1, 0, 1], device='cuda:0', dtype=torch.uint8)\n","5\n","rating_accumulators : 39\n","total_rating_samples : 56\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8)\n","4\n","rating_accumulators : 89\n","total_rating_samples : 115\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 0, 1, 1], device='cuda:0', dtype=torch.uint8)\n","3\n","rating_accumulators : 92\n","total_rating_samples : 120\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True,  True,  True, False], device='cuda:0')\n","actual : tensor([1, 1, 1, 1, 1, 0], device='cuda:0', dtype=torch.uint8)\n","correct_ratings : 6\n","rating_accumulators : 105\n","total_rating_samples : 138\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 0, 0, 1], device='cuda:0', dtype=torch.uint8)\n","4\n","rating_accumulators : 96\n","total_rating_samples : 125\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([True, True, True, True, True, True], device='cuda:0')\n","actual : tensor([1, 1, 0, 1, 1, 0], device='cuda:0', dtype=torch.uint8)\n","correct_ratings : 4\n","rating_accumulators : 109\n","total_rating_samples : 144\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([True, True, True, True, True, True, True], device='cuda:0')\n","actual : tensor([1, 0, 1, 0, 1, 1, 0], device='cuda:0', dtype=torch.uint8)\n","4\n","rating_accumulators : 43\n","total_rating_samples : 63\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 0, 1, 0], device='cuda:0', dtype=torch.uint8)\n","2\n","rating_accumulators : 98\n","total_rating_samples : 130\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 0, 1, 1], device='cuda:0', dtype=torch.uint8)\n","3\n","rating_accumulators : 101\n","total_rating_samples : 135\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([0, 0, 0, 0, 1], device='cuda:0', dtype=torch.uint8)\n","2\n","rating_accumulators : 103\n","total_rating_samples : 140\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8)\n","4\n","rating_accumulators : 107\n","total_rating_samples : 145\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 1, 0, 1], device='cuda:0', dtype=torch.uint8)\n","5\n","rating_accumulators : 112\n","total_rating_samples : 150\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True,  True,  True, False], device='cuda:0')\n","actual : tensor([1, 0, 1, 0, 1, 0], device='cuda:0', dtype=torch.uint8)\n","correct_ratings : 4\n","rating_accumulators : 113\n","total_rating_samples : 150\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True,  True,  True, False], device='cuda:0')\n","actual : tensor([1, 1, 1, 0, 1, 0], device='cuda:0', dtype=torch.uint8)\n","correct_ratings : 5\n","rating_accumulators : 118\n","total_rating_samples : 156\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True,  True,  True, False], device='cuda:0')\n","actual : tensor([0, 0, 1, 1, 1, 0], device='cuda:0', dtype=torch.uint8)\n","correct_ratings : 4\n","rating_accumulators : 122\n","total_rating_samples : 162\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([True, True, True, True, True, True, True], device='cuda:0')\n","actual : tensor([1, 0, 1, 0, 1, 1, 0], device='cuda:0', dtype=torch.uint8)\n","4\n","rating_accumulators : 47\n","total_rating_samples : 70\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8)\n","4\n","rating_accumulators : 116\n","total_rating_samples : 155\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([True, True, True, True, True, True], device='cuda:0')\n","actual : tensor([1, 1, 1, 0, 1, 0], device='cuda:0', dtype=torch.uint8)\n","correct_ratings : 4\n","rating_accumulators : 126\n","total_rating_samples : 168\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8)\n","4\n","rating_accumulators : 120\n","total_rating_samples : 160\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 0, 0, 1], device='cuda:0', dtype=torch.uint8)\n","4\n","rating_accumulators : 124\n","total_rating_samples : 165\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 1, 0, 1], device='cuda:0', dtype=torch.uint8)\n","5\n","rating_accumulators : 129\n","total_rating_samples : 170\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([True, True, True, True, True, True, True], device='cuda:0')\n","actual : tensor([1, 1, 1, 0, 1, 1, 0], device='cuda:0', dtype=torch.uint8)\n","5\n","rating_accumulators : 52\n","total_rating_samples : 77\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([0, 0, 0, 0, 1], device='cuda:0', dtype=torch.uint8)\n","2\n","rating_accumulators : 131\n","total_rating_samples : 175\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True,  True,  True, False], device='cuda:0')\n","actual : tensor([0, 1, 0, 1, 1, 0], device='cuda:0', dtype=torch.uint8)\n","correct_ratings : 4\n","rating_accumulators : 130\n","total_rating_samples : 174\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 0, 0, 1], device='cuda:0', dtype=torch.uint8)\n","4\n","rating_accumulators : 135\n","total_rating_samples : 180\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 1, 0, 1], device='cuda:0', dtype=torch.uint8)\n","5\n","rating_accumulators : 140\n","total_rating_samples : 185\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8)\n","4\n","rating_accumulators : 144\n","total_rating_samples : 190\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","1 , 99\n","Epoch [7/1000], Validation Loss: 1.4234, Classification Accuracy: 0.7879, Rating Accuracy (Deadlift): 0.7579, Rating Accuracy (Squat): 0.7471, Rating Accuracy (Lunges): 0.6753\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 0., 1., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([8.6621e-02, 9.9771e-01, 9.9974e-01, 5.8301e-01, 9.9989e-01, 9.7857e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7181224226951599\n","0 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0809e-01, 9.9562e-01, 9.9936e-01, 5.7606e-01, 9.9971e-01, 2.6581e-04],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4534718692302704\n","1 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 0., 1., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([3.3765e-02, 9.9982e-01, 9.9999e-01, 6.2711e-01, 1.0000e+00, 1.9809e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7273809313774109\n","2 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 0., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.4109e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5892388224601746\n","3 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([2.7228e-02, 9.9990e-01, 1.0000e+00, 6.3534e-01, 1.0000e+00, 8.1646e-07],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4608207643032074\n","4 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([5.7435e-02, 9.9925e-01, 9.9994e-01, 6.0867e-01, 9.9998e-01, 1.7571e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.45540469884872437\n","5 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.8482e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.38923880457878113\n","6 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 0., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.7878e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5892388224601746\n","7 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 4.6788e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.3892388343811035\n","8 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([5.2464e-02, 9.9942e-01, 9.9996e-01, 6.1696e-01, 9.9999e-01, 1.1932e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5668834447860718\n","9 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.8774e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.38923880457878113\n","10 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([6.2500e-02, 9.9907e-01, 9.9993e-01, 6.0991e-01, 9.9997e-01, 2.4490e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.454928457736969\n","11 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 0., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.7601e-12, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5892388224601746\n","12 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 0., 1., 1.], device='cuda:0') and ratings_output : tensor([8.4830e-02, 9.9784e-01, 9.9976e-01, 5.9814e-01, 9.9990e-01, 8.9700e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.553579568862915\n","13 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 0., 1., 0., 1., 1.], device='cuda:0') and ratings_output : tensor([4.4577e-02, 9.9964e-01, 9.9998e-01, 6.2590e-01, 9.9999e-01, 5.6114e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7263448238372803\n","14 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 5.960462772236497e-07\n","ratings : tensor([1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 4.0828e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.38923880457878113\n","15 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([6.0619e-02, 9.9921e-01, 9.9994e-01, 6.0828e-01, 9.9998e-01, 1.9217e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4652756154537201\n","16 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 8.511180931236595e-05\n","ratings : tensor([1., 1., 1., 0., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([0.9965, 0.0755, 0.9890, 0.0053, 0.9988, 0.8180, 0.0023],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.479402631521225\n","17 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([3.1991e-02, 9.9986e-01, 9.9999e-01, 6.3205e-01, 1.0000e+00, 1.3025e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6227493286132812\n","18 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.1231e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.38923880457878113\n","19 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([5.9081e-02, 9.9930e-01, 9.9995e-01, 6.0802e-01, 9.9998e-01, 1.6021e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5664905309677124\n","20 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 8.106198947643861e-06\n","ratings : tensor([1., 0., 0., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([1.0549e-02, 9.9999e-01, 1.0000e+00, 6.7015e-01, 1.0000e+00, 1.3259e-08],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.9006919860839844\n","21 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 4.768370445162873e-07\n","ratings : tensor([1., 0., 0., 0., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([0.9948, 0.0927, 0.9850, 0.0077, 0.9981, 0.7966, 0.0035],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6331247091293335\n","22 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 2.4187e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.38923880457878113\n","23 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 0., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([4.0800e-02, 9.9975e-01, 9.9999e-01, 6.1180e-01, 1.0000e+00, 3.2976e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6300116181373596\n","24 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 0., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([0.9951, 0.0928, 0.9857, 0.0072, 0.9982, 0.7987, 0.0032],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6187942028045654\n","25 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 0., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.5069e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5892388224601746\n","26 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 0., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.4052e-10, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5892388224601746\n","27 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 1., 0., 0.], device='cuda:0') and ratings_output : tensor([5.5221e-02, 9.9943e-01, 9.9996e-01, 5.9628e-01, 9.9999e-01, 1.1809e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6321730613708496\n","28 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 1.1920928244535389e-07\n","ratings : tensor([1., 1., 1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([0.9965, 0.0848, 0.9889, 0.0053, 0.9988, 0.8138, 0.0023],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5941197872161865\n","29 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([8.1323e-02, 9.9828e-01, 9.9982e-01, 5.8058e-01, 9.9993e-01, 6.3748e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5655196905136108\n","30 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 2.0265558760002023e-06\n","ratings : tensor([0., 1., 0., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 2.2732e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7892388701438904\n","31 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 5.722029527532868e-06\n","ratings : tensor([1., 1., 0., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 2.8547e-10, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5892388224601746\n","32 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 2.3841855067985307e-07\n","ratings : tensor([1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 4.1553e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.38923880457878113\n","33 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([7.2223e-02, 9.9874e-01, 9.9988e-01, 5.8050e-01, 9.9996e-01, 3.9665e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.45591065287590027\n","34 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 0., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([0.9950, 0.1021, 0.9850, 0.0074, 0.9982, 0.7938, 0.0033],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6182878613471985\n","35 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 1.1920928244535389e-07\n","ratings : tensor([0., 1., 1., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([2.8768e-02, 9.9989e-01, 1.0000e+00, 6.0883e-01, 1.0000e+00, 8.8637e-07],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5639656782150269\n","36 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([6.9963e-02, 9.9883e-01, 9.9990e-01, 5.7416e-01, 9.9996e-01, 3.5582e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5521599650382996\n","37 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([3.7987e-02, 9.9978e-01, 9.9999e-01, 5.8338e-01, 1.0000e+00, 2.7381e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.46478772163391113\n","38 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 1.1920928244535389e-07\n","ratings : tensor([0., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([4.5239e-02, 9.9964e-01, 9.9998e-01, 5.7250e-01, 9.9999e-01, 5.7957e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.46606335043907166\n","39 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 1.0728830375228426e-06\n","ratings : tensor([1., 1., 0., 0., 0.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.1256e-09, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7892387509346008\n","40 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 4.2259e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.38923880457878113\n","41 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 3.4570634852570947e-06\n","ratings : tensor([1., 1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([4.3118e-02, 9.9967e-01, 9.9998e-01, 5.7070e-01, 9.9999e-01, 5.1162e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6254678964614868\n","42 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([4.2927e-02, 9.9968e-01, 9.9998e-01, 5.7116e-01, 9.9999e-01, 4.9383e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5611389875411987\n","43 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.007422370370477438\n","ratings : tensor([1., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([1.1304e-02, 9.9999e-01, 1.0000e+00, 5.9793e-01, 1.0000e+00, 2.3815e-08],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4597782790660858\n","44 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([7.2316e-02, 9.9862e-01, 9.9987e-01, 5.5298e-01, 9.9995e-01, 4.5742e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.45757007598876953\n","45 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 2.2224e-10, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.3892388343811035\n","46 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([4.6143e-02, 9.9959e-01, 9.9998e-01, 5.6382e-01, 9.9999e-01, 7.2159e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4589763283729553\n","47 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 1.311301275563892e-06\n","ratings : tensor([1., 0., 0., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 3.7206e-10, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7892387509346008\n","48 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 0., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([5.5489e-02, 9.9934e-01, 9.9995e-01, 5.6306e-01, 9.9998e-01, 1.4752e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6341829299926758\n","49 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 0., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([4.8132e-02, 9.9955e-01, 9.9997e-01, 5.7181e-01, 9.9999e-01, 8.2030e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.633018434047699\n","50 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([6.7746e-02, 9.9884e-01, 9.9990e-01, 5.6862e-01, 9.9996e-01, 3.5316e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.45697805285453796\n","51 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 0., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 2.3882e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5892388224601746\n","52 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 7.152555099310121e-07\n","ratings : tensor([1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 2.9849e-10, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.3892388343811035\n","53 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 5.960446742392378e-06\n","ratings : tensor([1., 0., 1., 0., 1., 0., 0.], device='cuda:0') and ratings_output : tensor([0.9932, 0.1204, 0.9806, 0.0098, 0.9975, 0.7784, 0.0046],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6075043082237244\n","54 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 9.1780e-12, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.38923880457878113\n","55 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 5.960462772236497e-07\n","ratings : tensor([0., 0., 0., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 3.9678e-10, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.9892387390136719\n","56 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 0., 0., 1., 1.], device='cuda:0') and ratings_output : tensor([0.9945, 0.1164, 0.9833, 0.0081, 0.9981, 0.7810, 0.0037],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.763002336025238\n","57 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 0., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([3.6446e-02, 9.9978e-01, 9.9999e-01, 5.9586e-01, 1.0000e+00, 2.7200e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6245052814483643\n","58 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 0., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 7.0107e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5892388224601746\n","59 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 3.6954811548639555e-06\n","ratings : tensor([0., 0., 0., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([3.4471e-02, 9.9981e-01, 9.9999e-01, 6.0855e-01, 1.0000e+00, 2.2362e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.8977224230766296\n","60 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 0., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 2.6989e-10, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5892388224601746\n","61 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 0., 1., 1., 1., 0., 0.], device='cuda:0') and ratings_output : tensor([0.9943, 0.1235, 0.9829, 0.0081, 0.9981, 0.7757, 0.0037],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6059659719467163\n","62 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([4.2292e-02, 9.9967e-01, 9.9998e-01, 6.0713e-01, 9.9999e-01, 5.0907e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6233686208724976\n","63 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0011624491307884455\n","ratings : tensor([1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 2.5040e-09, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.38923895359039307\n","64 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 1.0847986231965479e-05\n","ratings : tensor([0., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([5.5491e-02, 9.9933e-01, 9.9995e-01, 6.0371e-01, 9.9998e-01, 1.5252e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.465098112821579\n","65 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([4.9304e-02, 9.9952e-01, 9.9997e-01, 6.1667e-01, 9.9999e-01, 9.2928e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4637993276119232\n","66 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([5.7113e-02, 9.9925e-01, 9.9994e-01, 6.1933e-01, 9.9998e-01, 1.8144e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5675475597381592\n","67 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 1.1920928244535389e-07\n","ratings : tensor([1., 0., 1., 0., 1., 1.], device='cuda:0') and ratings_output : tensor([6.2007e-02, 9.9904e-01, 9.9992e-01, 6.1971e-01, 9.9997e-01, 2.6566e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7241880297660828\n","68 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 0., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([4.8411e-02, 9.9950e-01, 9.9997e-01, 6.3198e-01, 9.9999e-01, 9.6430e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6294946074485779\n","69 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 6.6756979322235566e-06\n","ratings : tensor([1., 1., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([0.9967, 0.1065, 0.9889, 0.0048, 0.9990, 0.7918, 0.0020],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.47768568992614746\n","70 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 0., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0035e-10, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7892387509346008\n","71 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 1.6212332411669195e-05\n","ratings : tensor([0., 0., 0., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([0.9936, 0.1372, 0.9810, 0.0091, 0.9978, 0.7568, 0.0042],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7786210179328918\n","72 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 0., 1., 0., 1., 1.], device='cuda:0') and ratings_output : tensor([5.1846e-02, 9.9939e-01, 9.9996e-01, 6.3092e-01, 9.9999e-01, 1.3192e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7262692451477051\n","73 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 0., 1., 1.], device='cuda:0') and ratings_output : tensor([5.8865e-02, 9.9913e-01, 9.9993e-01, 6.2352e-01, 9.9998e-01, 2.2831e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5583438277244568\n","74 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 5.960462772236497e-07\n","ratings : tensor([1., 0., 1., 0., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([0.9947, 0.1317, 0.9834, 0.0076, 0.9983, 0.7624, 0.0034],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.49743151664733887\n","75 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 4.6381e-12, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.38923880457878113\n","76 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([0.9910, 0.1523, 0.9749, 0.0127, 0.9967, 0.7406, 0.0060],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5824721455574036\n","77 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 0., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([8.3048e-02, 9.9780e-01, 9.9975e-01, 6.0312e-01, 9.9990e-01, 9.4333e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6203651428222656\n","78 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([4.1487e-02, 9.9967e-01, 9.9998e-01, 6.3307e-01, 9.9999e-01, 5.0850e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4621714949607849\n","79 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 2.3563e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.38923880457878113\n","80 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([7.0735e-02, 9.9863e-01, 9.9987e-01, 6.0889e-01, 9.9995e-01, 4.5907e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5558352470397949\n","81 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 0., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 4.4083e-10, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5892388224601746\n","82 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 3.4247e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.38923880457878113\n","83 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([4.9729e-02, 9.9949e-01, 9.9997e-01, 6.2180e-01, 9.9999e-01, 1.0281e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.45524972677230835\n","84 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([3.9879e-02, 9.9973e-01, 9.9999e-01, 6.3072e-01, 1.0000e+00, 3.8977e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.46216797828674316\n","85 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.1652e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.38923880457878113\n","86 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 3.2811e-10, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.3892388343811035\n","87 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([1.2868e-01, 9.9289e-01, 9.9872e-01, 5.7859e-01, 9.9938e-01, 5.7825e-04],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4519420266151428\n","88 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 0., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([0.9954, 0.1255, 0.9853, 0.0067, 0.9986, 0.7663, 0.0029],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.49561333656311035\n","89 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 4.768370445162873e-07\n","ratings : tensor([1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 6.0329e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.3892388343811035\n","90 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 1.1920928244535389e-07\n","ratings : tensor([1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 7.6670e-09, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.3892391622066498\n","91 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([4.7296e-02, 9.9958e-01, 9.9997e-01, 6.2809e-01, 9.9999e-01, 7.5798e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4550766944885254\n","92 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([6.6458e-02, 9.9899e-01, 9.9991e-01, 6.1729e-01, 9.9997e-01, 2.9106e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5681440830230713\n","93 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([9.2781e-02, 9.9744e-01, 9.9969e-01, 6.0142e-01, 9.9987e-01, 1.2148e-04],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5533398985862732\n","94 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 1.1920928244535389e-07\n","ratings : tensor([1., 1., 1., 0., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([0.9941, 0.1338, 0.9821, 0.0086, 0.9981, 0.7553, 0.0038],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4789927005767822\n","95 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 3.576278118089249e-07\n","ratings : tensor([1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 2.7630e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.38923880457878113\n","96 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 1.1920928244535389e-07\n","ratings : tensor([1., 0., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([0.9885, 0.1639, 0.9699, 0.0163, 0.9955, 0.7267, 0.0079],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5010339617729187\n","97 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 1.1920928244535389e-07\n","ratings : tensor([1., 1., 0., 0., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([0.9957, 0.1194, 0.9862, 0.0066, 0.9986, 0.7751, 0.0028],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6190823316574097\n","98 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([3.3709e-02, 9.9985e-01, 9.9999e-01, 6.4688e-01, 1.0000e+00, 1.5252e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.46070727705955505\n","99 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([0.9919, 0.1448, 0.9773, 0.0120, 0.9970, 0.7522, 0.0055],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5840270519256592\n","100 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 2.3841855067985307e-07\n","ratings : tensor([0., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([4.4166e-02, 9.9970e-01, 9.9998e-01, 6.3529e-01, 1.0000e+00, 4.5941e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4622698724269867\n","101 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 0., 1., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([5.1667e-02, 9.9954e-01, 9.9997e-01, 6.3062e-01, 9.9999e-01, 8.6793e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7348819971084595\n","102 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([7.6121e-02, 9.9866e-01, 9.9987e-01, 6.1055e-01, 9.9995e-01, 4.5421e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4538229703903198\n","103 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 6.794906312279636e-06\n","ratings : tensor([0., 0., 1., 0., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([0.9897, 0.1589, 0.9724, 0.0153, 0.9960, 0.7403, 0.0073],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7857384085655212\n","104 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 6.5233e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.3892388343811035\n","105 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([3.1788e-02, 9.9988e-01, 1.0000e+00, 6.5043e-01, 1.0000e+00, 1.1192e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4603400230407715\n","106 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 1.1920928244535389e-07\n","ratings : tensor([0., 1., 0., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 2.9686e-10, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7892387509346008\n","107 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 1.4305104514278355e-06\n","ratings : tensor([0., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 5.1490e-10, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5892388224601746\n","108 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 2.7961e-10, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5892388224601746\n","109 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 0., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 2.1908e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7892388701438904\n","110 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 1.311301275563892e-06\n","ratings : tensor([1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 3.1412e-10, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.3892388343811035\n","111 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 4.768370445162873e-07\n","ratings : tensor([1., 1., 1., 1., 1., 0., 0.], device='cuda:0') and ratings_output : tensor([0.9911, 0.1510, 0.9758, 0.0134, 0.9966, 0.7508, 0.0062],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5843324661254883\n","112 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 1.1920928244535389e-07\n","ratings : tensor([1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 9.2706e-12, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.38923880457878113\n","113 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 0., 1., 0., 1., 1.], device='cuda:0') and ratings_output : tensor([5.6185e-02, 9.9944e-01, 9.9996e-01, 6.2754e-01, 9.9999e-01, 1.2090e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7255553603172302\n","114 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([6.6003e-02, 9.9912e-01, 9.9993e-01, 6.1873e-01, 9.9997e-01, 2.3795e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4541310667991638\n","115 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 5.483612312673358e-06\n","ratings : tensor([1., 0., 0., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 6.1207e-10, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7892387509346008\n","116 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 4.410734163684538e-06\n","ratings : tensor([1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 9.3897e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.3892388343811035\n","117 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.1299e-01, 9.9592e-01, 9.9940e-01, 5.9300e-01, 9.9973e-01, 2.5031e-04],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4520603120326996\n","118 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 0., 0., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([0.9931, 0.1426, 0.9803, 0.0106, 0.9976, 0.7583, 0.0047],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.8681694865226746\n","119 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 0., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 9.9048e-12, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7892388701438904\n","120 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([8.5807e-02, 9.9828e-01, 9.9982e-01, 6.0987e-01, 9.9993e-01, 6.6828e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.46741175651550293\n","121 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 4.2096e-10, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5892388224601746\n","122 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 1.0728830375228426e-06\n","ratings : tensor([1., 1., 1., 0., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([0.9968, 0.1180, 0.9894, 0.0051, 0.9991, 0.7834, 0.0020],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.47796162962913513\n","123 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 7.152555099310121e-07\n","ratings : tensor([1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 5.5838e-10, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.3892388343811035\n","124 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([7.2345e-02, 9.9895e-01, 9.9991e-01, 6.2170e-01, 9.9997e-01, 3.1343e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4655151963233948\n","125 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 2.2927e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.38923880457878113\n","126 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 0., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([0.9906, 0.1695, 0.9747, 0.0139, 0.9966, 0.7303, 0.0064],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6151673197746277\n","127 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 4.0531076592742465e-06\n","ratings : tensor([1., 0., 1., 0., 1., 0., 0.], device='cuda:0') and ratings_output : tensor([0.9906, 0.1789, 0.9743, 0.0139, 0.9967, 0.7271, 0.0063],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6078004240989685\n","128 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 3.5228e-10, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.3892388343811035\n","129 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 3.8514e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.38923880457878113\n","130 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([5.3258e-02, 9.9957e-01, 9.9997e-01, 6.4281e-01, 9.9999e-01, 8.1682e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5697550773620605\n","131 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 1.1920928244535389e-07\n","ratings : tensor([1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 2.6426e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.38923880457878113\n","132 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.2636e-01, 9.9452e-01, 9.9909e-01, 5.9639e-01, 9.9957e-01, 3.9534e-04],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4508838653564453\n","133 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 1.1920928244535389e-07\n","ratings : tensor([1., 1., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([0.9953, 0.1552, 0.9851, 0.0071, 0.9987, 0.7499, 0.0029],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.47643765807151794\n","134 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 0., 1., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([1.1754e-01, 9.9563e-01, 9.9933e-01, 6.0252e-01, 9.9970e-01, 2.8090e-04],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7175593376159668\n","135 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 0., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([7.2471e-02, 9.9897e-01, 9.9991e-01, 6.2942e-01, 9.9997e-01, 3.0709e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6196494102478027\n","136 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 2.729855441430118e-05\n","ratings : tensor([0., 0., 0., 0., 1.], device='cuda:0') and ratings_output : tensor([9.9999e-01, 1.0000e+00, 9.9999e-01, 2.7348e-08, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.9892367720603943\n","137 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 0., 1., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([1.0126e-01, 9.9737e-01, 9.9967e-01, 6.1276e-01, 9.9986e-01, 1.2941e-04],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7201247215270996\n","138 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 0., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 4.3750e-10, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7892387509346008\n","139 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 0., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([7.1119e-02, 9.9911e-01, 9.9992e-01, 6.3192e-01, 9.9997e-01, 2.4645e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6314613223075867\n","140 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0078e-10, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.3892388343811035\n","141 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 1.4305104514278355e-06\n","ratings : tensor([1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.7615e-09, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.3892389237880707\n","142 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 0., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([0.1642, 0.9887, 0.9975, 0.5829, 0.9987, 0.0012], device='cuda:0',\n","       grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6153203845024109\n","143 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([0.1821, 0.9845, 0.9961, 0.5776, 0.9979, 0.0020], device='cuda:0',\n","       grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.44857680797576904\n","144 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.4112e-01, 9.9365e-01, 9.9886e-01, 5.9707e-01, 9.9946e-01, 5.0191e-04],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4497414529323578\n","145 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 5.9022e-10, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.3892388343811035\n","146 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([1.1850e-01, 9.9661e-01, 9.9952e-01, 6.1215e-01, 9.9979e-01, 1.9312e-04],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.47024619579315186\n","147 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([1.1871e-01, 9.9671e-01, 9.9953e-01, 6.1632e-01, 9.9980e-01, 1.8517e-04],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5727354884147644\n","148 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([9.1900e-02, 9.9857e-01, 9.9985e-01, 6.3451e-01, 9.9994e-01, 5.2276e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.46649110317230225\n","149 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 1.4305104514278355e-06\n","ratings : tensor([1., 1., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([0.9815, 0.2273, 0.9559, 0.0258, 0.9926, 0.6835, 0.0129],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.476200670003891\n","150 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([1.4778e-01, 9.9340e-01, 9.9878e-01, 6.0496e-01, 9.9942e-01, 5.3881e-04],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.448863685131073\n","151 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 2.3841855067985307e-07\n","ratings : tensor([1., 0., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 7.2528e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5892388224601746\n","152 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.00034528967808000743\n","ratings : tensor([1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 4.9866e-09, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5892390608787537\n","153 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 0., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 3.6068e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5892388224601746\n","154 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 1.1920928244535389e-07\n","ratings : tensor([1., 1., 1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([0.9870, 0.2209, 0.9663, 0.0186, 0.9954, 0.6969, 0.0087],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.47420409321784973\n","155 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 4.768370445162873e-07\n","ratings : tensor([0., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([1.5322e-01, 9.9264e-01, 9.9858e-01, 6.0530e-01, 9.9931e-01, 6.3998e-04],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4740177392959595\n","156 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 1.1920928244535389e-07\n","ratings : tensor([1., 1., 0., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 3.3559e-10, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5892388224601746\n","157 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([6.8812e-02, 9.9941e-01, 9.9996e-01, 6.6425e-01, 9.9999e-01, 1.3662e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5734492540359497\n","158 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 4.172316494077677e-06\n","ratings : tensor([1., 0., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([0.9794, 0.2563, 0.9516, 0.0288, 0.9918, 0.6753, 0.0145],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5115863680839539\n","159 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 0., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 3.7275e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7892388701438904\n","160 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.2198e-01, 9.9644e-01, 9.9947e-01, 6.2562e-01, 9.9977e-01, 2.1212e-04],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6160441637039185\n","161 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 7.152555099310121e-07\n","ratings : tensor([1., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([0.1932, 0.9832, 0.9956, 0.5914, 0.9976, 0.0023], device='cuda:0',\n","       grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4470313787460327\n","162 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 0., 1., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([9.9782e-02, 9.9819e-01, 9.9979e-01, 6.4508e-01, 9.9992e-01, 7.6232e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7404717206954956\n","163 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 0., 0., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([0.1787, 0.9874, 0.9970, 0.5998, 0.9984, 0.0015], device='cuda:0',\n","       grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.8779759407043457\n","164 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 0., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 8.6463e-10, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5892388224601746\n","165 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 0., 0., 0.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 4.0254e-10, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7892388105392456\n","166 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0011343479854986072\n","ratings : tensor([0., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([1.3496e-01, 9.9462e-01, 9.9907e-01, 6.1836e-01, 9.9958e-01, 3.9693e-04],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4714784026145935\n","167 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([8.3410e-02, 9.9897e-01, 9.9990e-01, 6.5475e-01, 9.9997e-01, 3.2185e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4645683169364929\n","168 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 5.2944e-10, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.3892388343811035\n","169 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 2.0265558760002023e-06\n","ratings : tensor([1., 0., 0., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.6415e-10, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7892387509346008\n","170 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([5.4962e-02, 9.9970e-01, 9.9998e-01, 6.8256e-01, 9.9999e-01, 4.8858e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.45134520530700684\n","171 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([9.8091e-02, 9.9823e-01, 9.9980e-01, 6.4614e-01, 9.9992e-01, 7.3419e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4663827121257782\n","172 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 1.1920928244535389e-07\n","ratings : tensor([1., 0., 1., 0., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([0.9868, 0.2414, 0.9659, 0.0192, 0.9954, 0.6982, 0.0089],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5113153457641602\n","173 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([8.4171e-02, 9.9886e-01, 9.9989e-01, 6.5973e-01, 9.9996e-01, 3.7573e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.46435731649398804\n","174 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 0., 1., 0., 1., 0., 0.], device='cuda:0') and ratings_output : tensor([0.9857, 0.2459, 0.9639, 0.0212, 0.9948, 0.7001, 0.0099],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6119706630706787\n","175 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 0., 1., 0., 0., 1.], device='cuda:0') and ratings_output : tensor([4.5182e-02, 9.9981e-01, 9.9999e-01, 7.0470e-01, 1.0000e+00, 2.4490e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.9091854095458984\n","176 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 6.3503e-12, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.38923880457878113\n","177 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([5.2140e-02, 9.9969e-01, 9.9998e-01, 6.9584e-01, 9.9999e-01, 5.0400e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.45952463150024414\n","178 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([6.9480e-02, 9.9924e-01, 9.9994e-01, 6.7776e-01, 9.9998e-01, 2.0300e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.45046719908714294\n","179 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 4.6642e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5892388224601746\n","180 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 3.2543604902457446e-05\n","ratings : tensor([1., 1., 0., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.7748e-10, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5892388224601746\n","181 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 3.3051e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.38923880457878113\n","182 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 1.6689286894688848e-06\n","ratings : tensor([1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 2.6415e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.38923880457878113\n","183 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.8439e-10, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.3892388343811035\n","184 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 0., 1., 0., 0., 0., 0.], device='cuda:0') and ratings_output : tensor([0.9916, 0.2187, 0.9764, 0.0132, 0.9973, 0.7255, 0.0056],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.894641101360321\n","185 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([6.6914e-02, 9.9929e-01, 9.9994e-01, 6.8348e-01, 9.9998e-01, 1.8161e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4503501355648041\n","186 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 0., 0., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([3.8372e-02, 9.9985e-01, 9.9999e-01, 7.2550e-01, 1.0000e+00, 1.6396e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.9045442342758179\n","187 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([3.4119e-02, 9.9989e-01, 1.0000e+00, 7.3410e-01, 1.0000e+00, 1.0139e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4501991868019104\n","188 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([0.9948, 0.1918, 0.9842, 0.0086, 0.9985, 0.7421, 0.0033],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4739290475845337\n","189 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 0.0008083889842964709\n","ratings : tensor([1., 0., 1., 0., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([0.9952, 0.1851, 0.9854, 0.0082, 0.9986, 0.7454, 0.0030],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5017973780632019\n","190 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([9.3180e-02, 9.9806e-01, 9.9977e-01, 6.6762e-01, 9.9991e-01, 8.3681e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4492117166519165\n","191 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 1.1920928244535389e-07\n","ratings : tensor([0., 0., 1., 0., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([0.9946, 0.1829, 0.9844, 0.0092, 0.9984, 0.7420, 0.0035],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6444771885871887\n","192 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 3.814689989667386e-06\n","ratings : tensor([0., 0., 1., 0., 0., 0., 0.], device='cuda:0') and ratings_output : tensor([0.9904, 0.1962, 0.9758, 0.0158, 0.9965, 0.7235, 0.0066],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.8927604556083679\n","193 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([6.6707e-02, 9.9929e-01, 9.9994e-01, 6.9646e-01, 9.9998e-01, 1.8284e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.565720796585083\n","194 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([0.9960, 0.1469, 0.9885, 0.0072, 0.9988, 0.7618, 0.0025],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.47625482082366943\n","195 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([5.9999e-02, 9.9951e-01, 9.9997e-01, 7.0620e-01, 9.9999e-01, 1.0442e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4496356248855591\n","196 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([8.1435e-02, 9.9882e-01, 9.9989e-01, 6.8642e-01, 9.9996e-01, 3.9152e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4490402638912201\n","197 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 0., 0., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.5027e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.9892388582229614\n","198 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 7.152555099310121e-07\n","ratings : tensor([1., 1., 0., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 9.3182e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5892388224601746\n","199 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.1601e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.38923880457878113\n","200 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 3.3378546504536644e-06\n","ratings : tensor([1., 0., 0., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 7.6672e-10, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7892387509346008\n","201 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([3.1915e-02, 9.9993e-01, 1.0000e+00, 7.5753e-01, 1.0000e+00, 5.4988e-07],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5806962251663208\n","202 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([1.1724e-01, 9.9664e-01, 9.9951e-01, 6.6092e-01, 9.9979e-01, 1.9444e-04],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5579344034194946\n","203 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([4.7938e-02, 9.9980e-01, 9.9999e-01, 7.3026e-01, 1.0000e+00, 2.6666e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4572734236717224\n","204 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 0., 0., 0.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 2.1441e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7892388701438904\n","205 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 8.344646857949556e-07\n","ratings : tensor([1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 4.9069e-09, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.3892390727996826\n","206 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 2.3841855067985307e-07\n","ratings : tensor([0., 1., 1., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([5.6736e-02, 9.9968e-01, 9.9998e-01, 7.1764e-01, 9.9999e-01, 5.5074e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5783259272575378\n","207 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 9.7768e-12, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.38923880457878113\n","208 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 2.9201e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.38923880457878113\n","209 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 0., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 2.7862e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5892388224601746\n","210 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 0., 1., 0., 1., 0., 0.], device='cuda:0') and ratings_output : tensor([0.9958, 0.1394, 0.9886, 0.0074, 0.9987, 0.7634, 0.0026],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6067089438438416\n","211 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([9.4149e-02, 9.9848e-01, 9.9983e-01, 6.7511e-01, 9.9994e-01, 5.8370e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.46437883377075195\n","212 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 0., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 2.4995e-10, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5892388224601746\n","213 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 5.125986263010418e-06\n","ratings : tensor([1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0654e-09, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.3892388939857483\n","214 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 1.8954096958623268e-05\n","ratings : tensor([0., 1., 0., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([2.3927e-02, 9.9998e-01, 1.0000e+00, 7.6786e-01, 1.0000e+00, 1.1380e-07],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6198828220367432\n","215 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 3.576278118089249e-07\n","ratings : tensor([0., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 2.0259e-10, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5892388224601746\n","216 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 2.539125671319198e-05\n","ratings : tensor([1., 0., 0., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.3958e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7892388701438904\n","217 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([1.2680e-01, 9.9608e-01, 9.9939e-01, 6.4862e-01, 9.9974e-01, 2.4759e-04],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5558750033378601\n","218 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 0., 0., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([8.0181e-02, 9.9908e-01, 9.9992e-01, 6.8319e-01, 9.9997e-01, 2.7181e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.9097084999084473\n","219 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.7595e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.38923880457878113\n","220 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 0., 1., 1., 1., 0., 0.], device='cuda:0') and ratings_output : tensor([0.9955, 0.1334, 0.9882, 0.0080, 0.9986, 0.7581, 0.0028],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6046738028526306\n","221 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([4.5409e-02, 9.9984e-01, 9.9999e-01, 7.1853e-01, 1.0000e+00, 1.9469e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5774492621421814\n","222 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 0., 1., 0., 0., 0.], device='cuda:0') and ratings_output : tensor([7.0859e-02, 9.9936e-01, 9.9995e-01, 6.7876e-01, 9.9998e-01, 1.5791e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.9084541201591492\n","223 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 6.5936e-12, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.38923880457878113\n","224 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 0., 1., 1.], device='cuda:0') and ratings_output : tensor([1.3408e-01, 9.9502e-01, 9.9915e-01, 6.2200e-01, 9.9962e-01, 3.5783e-04],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5524204969406128\n","225 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 9.6510e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.3892388343811035\n","226 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 0., 1., 0., 1., 1.], device='cuda:0') and ratings_output : tensor([6.2480e-02, 9.9955e-01, 9.9997e-01, 6.6335e-01, 9.9999e-01, 9.4193e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7393882274627686\n","227 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 4.0174e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.38923880457878113\n","228 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.7834e-10, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.3892388343811035\n","229 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([0.9932, 0.1402, 0.9839, 0.0118, 0.9976, 0.7334, 0.0043],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4781239628791809\n","230 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([1.3625e-01, 9.9476e-01, 9.9908e-01, 6.0109e-01, 9.9959e-01, 3.8884e-04],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.44989013671875\n","231 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 0., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([1.0036e-01, 9.9803e-01, 9.9976e-01, 6.1017e-01, 9.9991e-01, 8.7950e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6353061199188232\n","232 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.2858e-10, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.3892388343811035\n","233 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 0., 1., 0., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([0.9969, 0.1041, 0.9919, 0.0059, 0.9991, 0.7612, 0.0018],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4947221279144287\n","234 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.9840e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.38923880457878113\n","235 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 3.4570634852570947e-06\n","ratings : tensor([1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 2.3498e-10, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.3892388343811035\n","236 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 0., 0., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 6.3780e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.9892387390136719\n","237 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 2.3741e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.38923880457878113\n","238 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.8999e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.38923880457878113\n","239 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 0., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 3.9067e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7892388105392456\n","240 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 3.7516e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.38923880457878113\n","241 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([1.2310e-01, 9.9611e-01, 9.9939e-01, 5.9081e-01, 9.9974e-01, 2.4839e-04],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.570415198802948\n","242 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([1.2105e-01, 9.9626e-01, 9.9942e-01, 5.8310e-01, 9.9975e-01, 2.3386e-04],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.47221511602401733\n","243 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([0.2155, 0.9732, 0.9913, 0.5480, 0.9949, 0.0048], device='cuda:0',\n","       grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.540292501449585\n","244 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 2.3841855067985307e-07\n","ratings : tensor([1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 7.6832e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.3892388343811035\n","245 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 0., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 6.3032e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5892388224601746\n","246 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 0., 1., 0., 1., 1.], device='cuda:0') and ratings_output : tensor([7.2503e-02, 9.9914e-01, 9.9992e-01, 5.8843e-01, 9.9997e-01, 2.5137e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7320682406425476\n","247 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([7.7945e-02, 9.9890e-01, 9.9989e-01, 5.7413e-01, 9.9996e-01, 3.6690e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.46881601214408875\n","248 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([9.3742e-02, 9.9793e-01, 9.9974e-01, 5.5909e-01, 9.9990e-01, 9.5759e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5643362998962402\n","249 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 0., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 3.2398e-12, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5892388224601746\n","250 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([8.4306e-02, 9.9840e-01, 9.9982e-01, 5.5205e-01, 9.9993e-01, 6.4608e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4707319140434265\n","251 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 0., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.1214e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5892388224601746\n","252 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 2.3841830625315197e-06\n","ratings : tensor([1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 6.3282e-10, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.3892388641834259\n","253 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 0., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 2.3295e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5892388224601746\n","254 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 9.5951e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.3892388343811035\n","255 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 0., 0., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([9.9834e-01, 7.7811e-02, 9.9538e-01, 3.4185e-03, 9.9956e-01, 7.8505e-01,\n","        9.1946e-04], device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6329410672187805\n","256 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 0., 1., 0., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([0.9971, 0.0862, 0.9928, 0.0057, 0.9991, 0.7664, 0.0017],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6355279088020325\n","257 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 0., 1., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([5.9020e-02, 9.9939e-01, 9.9995e-01, 5.5208e-01, 9.9998e-01, 1.5183e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7172322273254395\n","258 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 0., 1., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([5.8357e-02, 9.9937e-01, 9.9995e-01, 5.4073e-01, 9.9998e-01, 1.5825e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7160860300064087\n","259 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([3.5638e-02, 9.9983e-01, 9.9999e-01, 5.3295e-01, 1.0000e+00, 2.1779e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4617055356502533\n","260 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 1.1920928244535389e-07\n","ratings : tensor([1., 1., 0., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 2.2877e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5892388224601746\n","261 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 0., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([0.9976, 0.0727, 0.9941, 0.0050, 0.9993, 0.7802, 0.0014],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5921787619590759\n","262 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 1.1920928244535389e-07\n","ratings : tensor([1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.9536e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.38923880457878113\n","263 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([0.9981, 0.0616, 0.9953, 0.0041, 0.9994, 0.7879, 0.0011],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4804512560367584\n","264 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 0., 0., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([3.8698e-02, 9.9978e-01, 9.9999e-01, 5.2096e-01, 1.0000e+00, 3.1195e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.8823212385177612\n","265 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 7.2685e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.3892388343811035\n","266 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 2.3841855067985307e-07\n","ratings : tensor([0., 1., 1., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([7.3879e-02, 9.9868e-01, 9.9986e-01, 5.0415e-01, 9.9995e-01, 4.8496e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5567988157272339\n","267 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([9.1587e-02, 9.9755e-01, 9.9968e-01, 4.9200e-01, 9.9987e-01, 1.2393e-04],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.459880530834198\n","268 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 0., 1., 0., 1., 1.], device='cuda:0') and ratings_output : tensor([4.4237e-02, 9.9967e-01, 9.9998e-01, 4.7802e-01, 9.9999e-01, 5.9049e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7107364535331726\n","269 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 0., 1., 0., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([9.9845e-01, 5.3751e-02, 9.9608e-01, 3.4805e-03, 9.9955e-01, 7.9634e-01,\n","        8.7417e-04], device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4889248013496399\n","270 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([2.1888e-02, 9.9995e-01, 1.0000e+00, 4.5593e-01, 1.0000e+00, 3.3862e-07],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.47134047746658325\n","271 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 3.2066785934148356e-05\n","ratings : tensor([1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 8.8304e-10, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.3892388939857483\n","272 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([6.9473e-02, 9.9888e-01, 9.9989e-01, 4.6025e-01, 9.9996e-01, 3.7819e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4635963439941406\n","273 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 6.5893e-12, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.38923880457878113\n","274 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([1.4341e-01, 9.9087e-01, 9.9802e-01, 4.6783e-01, 9.9901e-01, 9.2196e-04],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.535807728767395\n","275 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 0., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([6.0224e-02, 9.9927e-01, 9.9994e-01, 4.4438e-01, 9.9998e-01, 2.0150e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6320043802261353\n","276 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 1., 0., 0.], device='cuda:0') and ratings_output : tensor([7.4341e-02, 9.9875e-01, 9.9987e-01, 4.4407e-01, 9.9995e-01, 4.5054e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6433101892471313\n","277 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 0., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([7.0399e-02, 9.9891e-01, 9.9989e-01, 4.4086e-01, 9.9996e-01, 3.6907e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6431594491004944\n","278 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 0., 0., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([9.9905e-01, 4.0772e-02, 9.9750e-01, 2.2929e-03, 9.9974e-01, 8.1881e-01,\n","        5.2152e-04], device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7716095447540283\n","279 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 0., 1., 0., 1., 1.], device='cuda:0') and ratings_output : tensor([5.9356e-02, 9.9934e-01, 9.9994e-01, 4.3696e-01, 9.9998e-01, 1.7232e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7151724100112915\n","280 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 4.410734163684538e-06\n","ratings : tensor([1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 4.9458e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.3892388343811035\n","281 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 1., 0., 0.], device='cuda:0') and ratings_output : tensor([7.4475e-02, 9.9875e-01, 9.9987e-01, 4.3922e-01, 9.9995e-01, 4.5444e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6436378955841064\n","282 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.3098e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7892388701438904\n","283 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0006631797295995057\n","ratings : tensor([0., 1., 0., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([1.0435e-02, 9.9999e-01, 1.0000e+00, 3.9331e-01, 1.0000e+00, 1.6441e-08],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6411699652671814\n","284 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 3.5835e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.38923880457878113\n","285 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([5.4121e-02, 9.9946e-01, 9.9996e-01, 4.3395e-01, 9.9999e-01, 1.2948e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4665136933326721\n","286 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 2.3841855067985307e-07\n","ratings : tensor([1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 2.5249e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.38923880457878113\n","287 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 0., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.6381e-12, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5892388224601746\n","288 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 7.5574e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5892388224601746\n","289 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([5.9466e-02, 9.9927e-01, 9.9994e-01, 4.4087e-01, 9.9998e-01, 2.0262e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5490278005599976\n","290 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 0., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 2.9218e-10, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7892387509346008\n","291 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 0., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([9.9914e-01, 3.5851e-02, 9.9776e-01, 2.1284e-03, 9.9976e-01, 8.2867e-01,\n","        4.7189e-04], device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6235859394073486\n","292 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 5.4192e-12, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.38923880457878113\n","293 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 2.3841855067985307e-07\n","ratings : tensor([1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 2.2571e-12, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.38923880457878113\n","294 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([4.2108e-02, 9.9971e-01, 9.9998e-01, 4.3470e-01, 9.9999e-01, 5.0649e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4744459390640259\n","295 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([8.1940e-02, 9.9813e-01, 9.9977e-01, 4.5195e-01, 9.9991e-01, 8.3692e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4631781280040741\n","296 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 1.1920928244535389e-07\n","ratings : tensor([1., 0., 0., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([9.9879e-01, 3.8971e-02, 9.9702e-01, 2.9448e-03, 9.9963e-01, 8.2524e-01,\n","        7.0032e-04], device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6284818053245544\n","297 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 3.576278118089249e-07\n","ratings : tensor([1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 2.4097e-12, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.38923880457878113\n","298 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.2026e-10, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.3892388343811035\n","299 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([3.7931e-02, 9.9976e-01, 9.9999e-01, 4.4267e-01, 1.0000e+00, 3.7294e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5473462343215942\n","300 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([6.5924e-02, 9.9892e-01, 9.9989e-01, 4.5323e-01, 9.9996e-01, 3.6506e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.47532105445861816\n","301 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([1.1823e-01, 9.9428e-01, 9.9895e-01, 4.6605e-01, 9.9951e-01, 4.5955e-04],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.45965465903282166\n","302 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 0., 0., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([6.9379e-02, 9.9868e-01, 9.9986e-01, 4.5975e-01, 9.9995e-01, 4.9540e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.8733622431755066\n","303 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 0., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 9.3137e-12, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5892388224601746\n","304 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 1.4305104514278355e-06\n","ratings : tensor([1., 1., 0., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.6700e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5892388224601746\n","305 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 0., 1., 0., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([9.9854e-01, 3.9586e-02, 9.9653e-01, 3.5379e-03, 9.9952e-01, 8.2743e-01,\n","        8.7571e-04], device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6045875549316406\n","306 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 1.1920928244535389e-07\n","ratings : tensor([0., 1., 0., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0020e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7892388701438904\n","307 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 0., 0., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([5.4415e-02, 9.9932e-01, 9.9994e-01, 4.5761e-01, 9.9998e-01, 1.8152e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.8835058212280273\n","308 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 2.3682e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7892388701438904\n","309 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 3.6965e-12, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.38923880457878113\n","310 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 1.6927575416048057e-05\n","ratings : tensor([0., 0., 0., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 5.3841e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.9892387390136719\n","311 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 3.6972e-12, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.38923880457878113\n","312 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 0., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 4.2536e-12, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5892388224601746\n","313 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 3.7634e-13, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.38923880457878113\n","314 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 1.1086402082582936e-05\n","ratings : tensor([1., 1., 1., 0., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([9.9974e-01, 1.6265e-02, 9.9926e-01, 7.8007e-04, 9.9994e-01, 8.8538e-01,\n","        1.3698e-04], device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.47961047291755676\n","315 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 0., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 2.6241e-12, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5892388224601746\n","316 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 0., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([4.2959e-02, 9.9964e-01, 9.9998e-01, 4.5118e-01, 9.9999e-01, 7.0346e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6401106715202332\n","317 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([5.6490e-02, 9.9922e-01, 9.9993e-01, 4.5534e-01, 9.9998e-01, 2.2718e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4743574261665344\n","318 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([3.7688e-02, 9.9972e-01, 9.9998e-01, 4.5143e-01, 1.0000e+00, 4.6774e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4666970670223236\n","319 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([8.6317e-02, 9.9739e-01, 9.9964e-01, 4.6704e-01, 9.9985e-01, 1.3929e-04],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4762873649597168\n","320 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 2.8013790142722428e-05\n","ratings : tensor([1., 0., 1., 0., 1., 0., 0.], device='cuda:0') and ratings_output : tensor([9.9962e-01, 1.8291e-02, 9.9896e-01, 1.1277e-03, 9.9989e-01, 8.7894e-01,\n","        2.1411e-04], device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6079604029655457\n","321 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 0., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 2.5285e-12, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5892388224601746\n","322 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 1.1920928244535389e-07\n","ratings : tensor([0., 0., 1., 0., 0., 0.], device='cuda:0') and ratings_output : tensor([2.3963e-02, 9.9991e-01, 1.0000e+00, 4.5796e-01, 1.0000e+00, 9.1038e-07],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.8810302019119263\n","323 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([4.0291e-02, 9.9964e-01, 9.9998e-01, 4.6497e-01, 9.9999e-01, 7.0374e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.47233062982559204\n","324 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 1.1920928244535389e-07\n","ratings : tensor([1., 1., 1., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([1.4898e-02, 9.9997e-01, 1.0000e+00, 4.6063e-01, 1.0000e+00, 1.7669e-07],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5447372198104858\n","325 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 4.768370445162873e-07\n","ratings : tensor([1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 6.5016e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.3892388343811035\n","326 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 0., 1., 0., 1., 1.], device='cuda:0') and ratings_output : tensor([2.6438e-02, 9.9986e-01, 9.9999e-01, 4.6540e-01, 1.0000e+00, 1.5954e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7109217047691345\n","327 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 0., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.3382e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7892388701438904\n","328 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([3.5626e-02, 9.9970e-01, 9.9998e-01, 4.6413e-01, 9.9999e-01, 5.2041e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4719853103160858\n","329 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 7.7000e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.3892388343811035\n","330 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 1.1920928244535389e-07\n","ratings : tensor([0., 1., 0., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([3.4802e-02, 9.9970e-01, 9.9998e-01, 4.6282e-01, 9.9999e-01, 5.3525e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6386637091636658\n","331 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 0., 0., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([9.9873e-01, 3.1040e-02, 9.9705e-01, 3.2488e-03, 9.9956e-01, 8.4132e-01,\n","        7.7371e-04], device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.8859845995903015\n","332 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 2.5392e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.38923880457878113\n","333 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.7898e-12, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5892388224601746\n","334 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 0., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([9.9897e-01, 2.7130e-02, 9.9756e-01, 2.7290e-03, 9.9966e-01, 8.4450e-01,\n","        6.1597e-04], device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6228832602500916\n","335 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 2.1857e-12, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5892388224601746\n","336 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 0., 1., 0., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([9.9941e-01, 2.0094e-02, 9.9851e-01, 1.6935e-03, 9.9982e-01, 8.5951e-01,\n","        3.3933e-04], device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6061634421348572\n","337 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([5.0444e-02, 9.9923e-01, 9.9993e-01, 4.6866e-01, 9.9998e-01, 2.2119e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4645739197731018\n","338 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0099e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5892388224601746\n","339 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 0., 1., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([1.1603e-01, 9.9302e-01, 9.9865e-01, 4.8000e-01, 9.9934e-01, 6.2100e-04],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.70452880859375\n","340 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 1.0728830375228426e-06\n","ratings : tensor([0., 1., 0., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.5344e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7892388701438904\n","341 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 0., 0., 0., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([9.9913e-01, 2.3885e-02, 9.9791e-01, 2.3781e-03, 9.9972e-01, 8.4062e-01,\n","        5.0655e-04], device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.769824743270874\n","342 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 0., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 3.8738e-12, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5892388224601746\n","343 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 0., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.2087e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5892388224601746\n","344 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 1., 0., 0.], device='cuda:0') and ratings_output : tensor([2.2588e-02, 9.9989e-01, 1.0000e+00, 4.6666e-01, 1.0000e+00, 1.1377e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6373769640922546\n","345 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 0., 1., 0., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([9.9886e-01, 2.6604e-02, 9.9735e-01, 3.0230e-03, 9.9962e-01, 8.2795e-01,\n","        6.7457e-04], device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.48544374108314514\n","346 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 2.9802276912960224e-06\n","ratings : tensor([0., 0., 0., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 2.1997e-10, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.9892387390136719\n","347 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([2.6195e-02, 9.9984e-01, 9.9999e-01, 4.7225e-01, 1.0000e+00, 1.9952e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.47065895795822144\n","348 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.00034457468427717686\n","ratings : tensor([0., 1., 0., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.7595e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7892388701438904\n","349 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 0., 1., 0., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([9.9990e-01, 7.2286e-03, 9.9970e-01, 3.6589e-04, 9.9998e-01, 8.9661e-01,\n","        4.9578e-05], device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7664545774459839\n","350 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 1.9311717551317997e-05\n","ratings : tensor([0., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([2.8792e-02, 9.9979e-01, 9.9999e-01, 4.7986e-01, 1.0000e+00, 3.0177e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4703946113586426\n","351 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 0., 0., 0.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 3.9618e-12, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7892388701438904\n","352 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([1.7713e-02, 9.9993e-01, 1.0000e+00, 4.8801e-01, 1.0000e+00, 5.2328e-07],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4689359664916992\n","353 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 0., 1., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([7.0841e-02, 9.9791e-01, 9.9975e-01, 4.9947e-01, 9.9990e-01, 9.8901e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7106083631515503\n","354 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 4.9779e-12, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.38923880457878113\n","355 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 0., 1., 0., 0.], device='cuda:0') and ratings_output : tensor([9.9957e-01, 1.4882e-02, 9.9889e-01, 1.3143e-03, 9.9988e-01, 8.5875e-01,\n","        2.4008e-04], device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7463722825050354\n","356 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 0., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([9.9889e-01, 2.3840e-02, 9.9744e-01, 2.9850e-03, 9.9963e-01, 8.2399e-01,\n","        6.5587e-04], device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4819079637527466\n","357 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([2.0896e-02, 9.9990e-01, 1.0000e+00, 5.0854e-01, 1.0000e+00, 1.0402e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4679122865200043\n","358 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([8.5362e-02, 9.9651e-01, 9.9949e-01, 5.1029e-01, 9.9978e-01, 2.1442e-04],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4592929780483246\n","359 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([3.0470e-02, 9.9972e-01, 9.9998e-01, 5.2641e-01, 1.0000e+00, 4.5408e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5502735376358032\n","360 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 0., 1., 0., 0.], device='cuda:0') and ratings_output : tensor([9.9945e-01, 1.6058e-02, 9.9865e-01, 1.6019e-03, 9.9984e-01, 8.4582e-01,\n","        3.0355e-04], device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7450181841850281\n","361 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 4.8992e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.3892388343811035\n","362 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([2.1613e-02, 9.9988e-01, 1.0000e+00, 5.3558e-01, 1.0000e+00, 1.2555e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.46269291639328003\n","363 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 1.1920928244535389e-07\n","ratings : tensor([1., 1., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([9.9884e-01, 2.3955e-02, 9.9735e-01, 3.0893e-03, 9.9962e-01, 8.1348e-01,\n","        6.7804e-04], device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.48202672600746155\n","364 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 2.4332e-12, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.38923880457878113\n","365 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([2.0967e-02, 9.9989e-01, 1.0000e+00, 5.4401e-01, 1.0000e+00, 1.1303e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5528968572616577\n","366 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 0., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([2.4115e-02, 9.9985e-01, 9.9999e-01, 5.4546e-01, 1.0000e+00, 1.7818e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6325434446334839\n","367 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 5.960462772236497e-07\n","ratings : tensor([1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 9.0109e-12, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5892388224601746\n","368 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 1.6689286894688848e-06\n","ratings : tensor([0., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0997e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5892388224601746\n","369 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 1.9073468138230965e-06\n","ratings : tensor([1., 1., 0., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 4.1674e-10, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5892388224601746\n","370 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 0., 0., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([9.9952e-01, 1.4918e-02, 9.9881e-01, 1.4149e-03, 9.9987e-01, 8.3836e-01,\n","        2.5636e-04], device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6244329810142517\n","371 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 9.9397e-12, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.38923880457878113\n","372 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 0., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([2.2964e-02, 9.9987e-01, 9.9999e-01, 5.5204e-01, 1.0000e+00, 1.5073e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6320676803588867\n","373 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([0.1267, 0.9901, 0.9979, 0.5289, 0.9989, 0.0010], device='cuda:0',\n","       grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4553415775299072\n","374 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 9.417489309271332e-06\n","ratings : tensor([1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 2.1954e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.38923880457878113\n","375 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 2.4970e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.38923880457878113\n","376 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([1.0430e-01, 9.9413e-01, 9.9897e-01, 5.3794e-01, 9.9951e-01, 4.7065e-04],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4562397003173828\n","377 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([3.6026e-02, 9.9961e-01, 9.9998e-01, 5.6925e-01, 9.9999e-01, 7.5967e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.45947322249412537\n","378 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 2.3841855067985307e-07\n","ratings : tensor([1., 1., 1., 1., 0., 0.], device='cuda:0') and ratings_output : tensor([1.9791e-02, 9.9991e-01, 1.0000e+00, 5.9487e-01, 1.0000e+00, 8.1065e-07],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6259276866912842\n","379 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 9.2734e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.3892388343811035\n","380 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 0., 0., 0.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 3.3261e-12, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7892388701438904\n","381 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 6.9937e-10, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.3892388939857483\n","382 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 4.1959e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.38923880457878113\n","383 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 1.1920928244535389e-07\n","ratings : tensor([1., 1., 0., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([7.5333e-02, 9.9769e-01, 9.9971e-01, 5.6928e-01, 9.9988e-01, 1.1485e-04],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6230177879333496\n","384 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([4.8099e-02, 9.9930e-01, 9.9994e-01, 5.9523e-01, 9.9998e-01, 1.8871e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4649693965911865\n","385 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 1.2397689715726301e-05\n","ratings : tensor([1., 1., 0., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 2.3455e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5892388224601746\n","386 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([9.9950e-01, 1.5391e-02, 9.9875e-01, 1.4785e-03, 9.9986e-01, 8.3626e-01,\n","        2.7105e-04], device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.481638103723526\n","387 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([2.7516e-02, 9.9983e-01, 9.9999e-01, 6.2828e-01, 1.0000e+00, 2.2383e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6233366131782532\n","388 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 0., 0., 0.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 3.6915e-12, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7892388701438904\n","389 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 0., 1., 0., 1., 1.], device='cuda:0') and ratings_output : tensor([7.8562e-02, 9.9760e-01, 9.9970e-01, 5.9925e-01, 9.9987e-01, 1.2157e-04],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7204794883728027\n","390 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 1.1920928244535389e-07\n","ratings : tensor([1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0040e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.38923880457878113\n","391 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 0., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([3.6816e-02, 9.9967e-01, 9.9998e-01, 6.4226e-01, 9.9999e-01, 6.0096e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6279088854789734\n","392 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 3.6088e-10, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.3892388343811035\n","393 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.6984e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.38923880457878113\n","394 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 1.9073468138230965e-06\n","ratings : tensor([1., 0., 0., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.1004e-10, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7892387509346008\n","395 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 1.1920928244535389e-07\n","ratings : tensor([1., 0., 1., 0., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([9.9971e-01, 1.1541e-02, 9.9924e-01, 9.0826e-04, 9.9993e-01, 8.5383e-01,\n","        1.4905e-04], device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4829378128051758\n","396 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 3.576278118089249e-07\n","ratings : tensor([1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 7.8164e-10, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.3892388939857483\n","397 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 0., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([9.9965e-01, 1.2694e-02, 9.9909e-01, 1.0834e-03, 9.9991e-01, 8.5181e-01,\n","        1.8689e-04], device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.48297613859176636\n","398 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 1.1920928244535389e-07\n","ratings : tensor([1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 5.7255e-12, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.38923880457878113\n","399 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([2.0197e-02, 9.9993e-01, 1.0000e+00, 6.7998e-01, 1.0000e+00, 5.9744e-07],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5710171461105347\n","400 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 7.152555099310121e-07\n","ratings : tensor([1., 0., 1., 0., 1., 0., 0.], device='cuda:0') and ratings_output : tensor([9.9955e-01, 1.4335e-02, 9.9886e-01, 1.3540e-03, 9.9987e-01, 8.5002e-01,\n","        2.4884e-04], device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6047943830490112\n","401 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([3.4229e-02, 9.9974e-01, 9.9999e-01, 6.6216e-01, 1.0000e+00, 4.2930e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4598867893218994\n","402 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([7.4090e-02, 9.9811e-01, 9.9978e-01, 6.2961e-01, 9.9991e-01, 8.5361e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5701913833618164\n","403 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 1.1920928244535389e-07\n","ratings : tensor([1., 0., 1., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([1.0832e-01, 9.9466e-01, 9.9909e-01, 6.1015e-01, 9.9958e-01, 4.1059e-04],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.719017505645752\n","404 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 0., 1., 0., 0., 1.], device='cuda:0') and ratings_output : tensor([6.2834e-02, 9.9877e-01, 9.9988e-01, 6.4181e-01, 9.9995e-01, 4.4310e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.90362548828125\n","405 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 9.536738616588991e-07\n","ratings : tensor([0., 0., 1., 0., 0., 0.], device='cuda:0') and ratings_output : tensor([2.0895e-02, 9.9992e-01, 1.0000e+00, 6.9523e-01, 1.0000e+00, 6.4399e-07],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.9060880541801453\n","406 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([2.6202e-02, 9.9987e-01, 9.9999e-01, 6.7703e-01, 1.0000e+00, 1.5520e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4583618640899658\n","407 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 0., 0., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([2.6557e-02, 9.9986e-01, 9.9999e-01, 6.7327e-01, 1.0000e+00, 1.6736e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.9041241407394409\n","408 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 3.099436753473128e-06\n","ratings : tensor([1., 0., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 3.2170e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5892388224601746\n","409 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([0.1740, 0.9792, 0.9941, 0.5713, 0.9966, 0.0033], device='cuda:0',\n","       grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.45006489753723145\n","410 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 5.304672595229931e-05\n","ratings : tensor([0., 0., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([1.8007e-02, 9.9994e-01, 1.0000e+00, 6.7639e-01, 1.0000e+00, 4.1796e-07],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6243607997894287\n","411 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 1.1920922133867862e-06\n","ratings : tensor([1., 0., 0., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([7.6654e-02, 9.9780e-01, 9.9973e-01, 6.0982e-01, 9.9989e-01, 1.0615e-04],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.888434886932373\n","412 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 0., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 6.4337e-12, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5892388224601746\n","413 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 1.1920928244535389e-07\n","ratings : tensor([0., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 2.9317e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5892388224601746\n","414 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 0., 0., 0., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([9.9847e-01, 2.7184e-02, 9.9663e-01, 3.9233e-03, 9.9946e-01, 8.0922e-01,\n","        9.2588e-04], device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.744282603263855\n","415 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([5.8243e-02, 9.9895e-01, 9.9990e-01, 6.1889e-01, 9.9996e-01, 3.4514e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.46446555852890015\n","416 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([7.8271e-02, 9.9776e-01, 9.9972e-01, 6.0357e-01, 9.9989e-01, 1.0964e-04],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4541163444519043\n","417 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 0., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([3.3431e-02, 9.9975e-01, 9.9999e-01, 6.4066e-01, 1.0000e+00, 3.9024e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6277102828025818\n","418 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 0., 1., 0., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([9.9962e-01, 1.2902e-02, 9.9903e-01, 1.1621e-03, 9.9990e-01, 8.4945e-01,\n","        2.0469e-04], device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.48325803875923157\n","419 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 0., 0., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.9081e-10, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7892387509346008\n","420 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([5.4613e-02, 9.9912e-01, 9.9992e-01, 6.2090e-01, 9.9997e-01, 2.6456e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4549259841442108\n","421 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 7.271740287251305e-06\n","ratings : tensor([1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.1885e-10, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.3892388343811035\n","422 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([8.3313e-02, 9.9730e-01, 9.9964e-01, 6.0369e-01, 9.9985e-01, 1.4456e-04],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5682352185249329\n","423 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 0., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.1472e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5892388224601746\n","424 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 1.7881377516459906e-06\n","ratings : tensor([1., 1., 0., 0., 0.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 3.9482e-12, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7892388701438904\n","425 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 0., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 9.0753e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5892388224601746\n","426 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.2303e-01, 9.9229e-01, 9.9849e-01, 5.8416e-01, 9.9926e-01, 7.1306e-04],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.47249075770378113\n","427 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([9.5250e-02, 9.9609e-01, 9.9941e-01, 5.9768e-01, 9.9974e-01, 2.5455e-04],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6197986602783203\n","428 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 0., 1., 0., 1., 1.], device='cuda:0') and ratings_output : tensor([6.2016e-02, 9.9873e-01, 9.9987e-01, 6.2001e-01, 9.9995e-01, 4.6114e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7241830825805664\n","429 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 2.2919e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.38923880457878113\n","430 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 0., 1., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([9.9867e-01, 2.4807e-02, 9.9703e-01, 3.4605e-03, 9.9955e-01, 8.0594e-01,\n","        7.8681e-04], device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.9101933240890503\n","431 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([1.2431e-01, 9.9203e-01, 9.9842e-01, 5.8532e-01, 9.9922e-01, 7.5255e-04],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5495085716247559\n","432 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 0., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([9.9838e-01, 2.7325e-02, 9.9645e-01, 4.1106e-03, 9.9943e-01, 7.9915e-01,\n","        9.7465e-04], device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.482876718044281\n","433 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([4.6757e-02, 9.9939e-01, 9.9995e-01, 6.3015e-01, 9.9998e-01, 1.5080e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6216734647750854\n","434 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 2.622600959512056e-06\n","ratings : tensor([1., 1., 0., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([9.9885e-01, 2.2708e-02, 9.9738e-01, 3.0435e-03, 9.9961e-01, 8.1451e-01,\n","        6.7714e-04], device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6244579553604126\n","435 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 0., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([2.9489e-02, 9.9982e-01, 9.9999e-01, 6.4970e-01, 1.0000e+00, 2.4276e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6268274784088135\n","436 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([7.6383e-02, 9.9800e-01, 9.9976e-01, 6.0885e-01, 9.9990e-01, 9.3044e-05],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.45394206047058105\n","437 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([0.9981, 0.0299, 0.9958, 0.0048, 0.9993, 0.7996, 0.0012],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5962958335876465\n","438 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.8645e-10, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.3892388343811035\n","439 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 3.1674e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.38923880457878113\n","440 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([0.1646, 0.9832, 0.9956, 0.5715, 0.9975, 0.0024], device='cuda:0',\n","       grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.45040711760520935\n","441 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([8.7625e-02, 9.9704e-01, 9.9959e-01, 6.0730e-01, 9.9983e-01, 1.6681e-04],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.4677990674972534\n","442 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 2.2452e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7892388701438904\n","443 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([1.0842e-01, 9.9519e-01, 9.9920e-01, 6.0087e-01, 9.9963e-01, 3.5358e-04],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.570265531539917\n","444 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 5.5874e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.3892388343811035\n","445 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 0., 1., 0., 1., 1.], device='cuda:0') and ratings_output : tensor([7.9606e-02, 9.9788e-01, 9.9974e-01, 6.1810e-01, 9.9989e-01, 1.0246e-04],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7224627733230591\n","446 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 5.5540e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.3892388343811035\n","447 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1., 0., 0.], device='cuda:0') and ratings_output : tensor([9.9884e-01, 2.3072e-02, 9.9735e-01, 3.0566e-03, 9.9961e-01, 8.1714e-01,\n","        6.8771e-04], device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5986664295196533\n","448 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 0., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 7.3093e-10, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5892388224601746\n","449 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 3.2241e-10, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.3892388343811035\n","450 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 0., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 2.6772e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5892388224601746\n","451 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([3.7741e-02, 9.9972e-01, 9.9998e-01, 6.5491e-01, 1.0000e+00, 4.8719e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5697497129440308\n","452 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([9.9860e-01, 2.6247e-02, 9.9684e-01, 3.6160e-03, 9.9952e-01, 8.0306e-01,\n","        8.3729e-04], device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.48221051692962646\n","453 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 1.2159273865108844e-05\n","ratings : tensor([1., 1., 1., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.7827e-10, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.3892388343811035\n","454 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 0., 1., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 4.2006e-10, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5892388224601746\n","455 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([2], device='cuda:0') and predicted activity : tensor([2], device='cuda:0')\n","activity loss: 1.2159273865108844e-05\n","ratings : tensor([0., 1., 1., 0., 0., 1., 1.], device='cuda:0') and ratings_output : tensor([9.9836e-01, 2.9234e-02, 9.9634e-01, 4.1677e-03, 9.9943e-01, 7.9359e-01,\n","        9.9077e-04], device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.7683956027030945\n","456 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 0., 0., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.1326e-09, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.9892385601997375\n","457 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.8797e-10, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.3892388343811035\n","458 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([4.0470e-02, 9.9966e-01, 9.9998e-01, 6.4667e-01, 9.9999e-01, 6.3306e-06],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.46130305528640747\n","459 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 0., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([0.2014, 0.9708, 0.9903, 0.5615, 0.9941, 0.0056], device='cuda:0',\n","       grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.6144952774047852\n","460 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 5.4101e-11, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.3892388343811035\n","461 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 0., 1., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([0.1695, 0.9830, 0.9954, 0.5714, 0.9974, 0.0024], device='cuda:0',\n","       grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.709139347076416\n","462 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([0., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([8.2627e-02, 9.9784e-01, 9.9973e-01, 6.0746e-01, 9.9989e-01, 1.0600e-04],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.46730586886405945\n","463 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([0.2095, 0.9679, 0.9889, 0.5573, 0.9932, 0.0065], device='cuda:0',\n","       grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5422903299331665\n","464 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 1., 1., 0.], device='cuda:0') and ratings_output : tensor([0.2468, 0.9465, 0.9772, 0.5466, 0.9847, 0.0143], device='cuda:0',\n","       grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.44985872507095337\n","465 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([0], device='cuda:0') and predicted activity : tensor([0], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 0., 1.], device='cuda:0') and ratings_output : tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 6.8001e-10, 1.0000e+00],\n","       device='cuda:0', grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.3892388939857483\n","466 and data_size: 468 and epoch: 8\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","real activity : tensor([1], device='cuda:0') and predicted activity : tensor([1], device='cuda:0')\n","activity loss: 0.0\n","ratings : tensor([1., 1., 1., 0., 1., 0.], device='cuda:0') and ratings_output : tensor([0.1698, 0.9841, 0.9958, 0.5677, 0.9977, 0.0022], device='cuda:0',\n","       grad_fn=\u003cSigmoidBackward0\u003e)\n","feature loss: 0.5447801947593689\n","467 and data_size: 468 and epoch: 8\n","Epoch [8/1000], Training Loss: 0.5603\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([True, True, True, True, True, True], device='cuda:0')\n","actual : tensor([1, 0, 1, 0, 1, 0], device='cuda:0', dtype=torch.uint8)\n","correct_ratings : 3\n","rating_accumulators : 3\n","total_rating_samples : 6\n","0 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([True, True, True, True, True, True, True], device='cuda:0')\n","actual : tensor([1, 1, 1, 1, 1, 1, 0], device='cuda:0', dtype=torch.uint8)\n","6\n","rating_accumulators : 6\n","total_rating_samples : 7\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 0, 0, 1], device='cuda:0', dtype=torch.uint8)\n","4\n","rating_accumulators : 4\n","total_rating_samples : 5\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 1, 0, 1], device='cuda:0', dtype=torch.uint8)\n","5\n","rating_accumulators : 9\n","total_rating_samples : 10\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([True, True, True, True, True, True], device='cuda:0')\n","actual : tensor([1, 0, 1, 0, 1, 0], device='cuda:0', dtype=torch.uint8)\n","correct_ratings : 3\n","rating_accumulators : 6\n","total_rating_samples : 12\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 0, 0, 1], device='cuda:0', dtype=torch.uint8)\n","4\n","rating_accumulators : 13\n","total_rating_samples : 15\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 1, 0, 1], device='cuda:0', dtype=torch.uint8)\n","5\n","rating_accumulators : 18\n","total_rating_samples : 20\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True,  True,  True, False], device='cuda:0')\n","actual : tensor([0, 1, 0, 1, 1, 0], device='cuda:0', dtype=torch.uint8)\n","correct_ratings : 4\n","rating_accumulators : 10\n","total_rating_samples : 18\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True,  True,  True, False], device='cuda:0')\n","actual : tensor([0, 0, 1, 0, 1, 1], device='cuda:0', dtype=torch.uint8)\n","correct_ratings : 2\n","rating_accumulators : 12\n","total_rating_samples : 24\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([0, 0, 1, 0, 1], device='cuda:0', dtype=torch.uint8)\n","3\n","rating_accumulators : 21\n","total_rating_samples : 25\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 0, 1, 1], device='cuda:0', dtype=torch.uint8)\n","3\n","rating_accumulators : 24\n","total_rating_samples : 30\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([True, True, True, True, True, True, True], device='cuda:0')\n","actual : tensor([1, 1, 0, 0, 1, 1, 1], device='cuda:0', dtype=torch.uint8)\n","5\n","rating_accumulators : 11\n","total_rating_samples : 14\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([True, True, True, True, True, True, True], device='cuda:0')\n","actual : tensor([1, 1, 1, 0, 1, 0, 1], device='cuda:0', dtype=torch.uint8)\n","5\n","rating_accumulators : 16\n","total_rating_samples : 21\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True,  True,  True, False], device='cuda:0')\n","actual : tensor([1, 1, 1, 1, 1, 0], device='cuda:0', dtype=torch.uint8)\n","correct_ratings : 6\n","rating_accumulators : 18\n","total_rating_samples : 30\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([True, True, True, True, True, True, True], device='cuda:0')\n","actual : tensor([1, 1, 1, 0, 1, 1, 0], device='cuda:0', dtype=torch.uint8)\n","5\n","rating_accumulators : 21\n","total_rating_samples : 28\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([True, True, True, True, True, True], device='cuda:0')\n","actual : tensor([1, 1, 1, 0, 1, 0], device='cuda:0', dtype=torch.uint8)\n","correct_ratings : 4\n","rating_accumulators : 22\n","total_rating_samples : 36\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([True, True, True, True, True, True], device='cuda:0')\n","actual : tensor([1, 1, 0, 1, 1, 0], device='cuda:0', dtype=torch.uint8)\n","correct_ratings : 4\n","rating_accumulators : 26\n","total_rating_samples : 42\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 0, 1, 1], device='cuda:0', dtype=torch.uint8)\n","3\n","rating_accumulators : 27\n","total_rating_samples : 35\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8)\n","4\n","rating_accumulators : 31\n","total_rating_samples : 40\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8)\n","4\n","rating_accumulators : 35\n","total_rating_samples : 45\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 1, 0, 1], device='cuda:0', dtype=torch.uint8)\n","5\n","rating_accumulators : 40\n","total_rating_samples : 50\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([True, True, True, True, True, True], device='cuda:0')\n","actual : tensor([1, 1, 1, 0, 1, 0], device='cuda:0', dtype=torch.uint8)\n","correct_ratings : 4\n","rating_accumulators : 30\n","total_rating_samples : 48\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8)\n","4\n","rating_accumulators : 44\n","total_rating_samples : 55\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([True, True, True, True, True, True], device='cuda:0')\n","actual : tensor([1, 1, 1, 1, 1, 0], device='cuda:0', dtype=torch.uint8)\n","correct_ratings : 5\n","rating_accumulators : 35\n","total_rating_samples : 54\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 1, 0, 1], device='cuda:0', dtype=torch.uint8)\n","5\n","rating_accumulators : 49\n","total_rating_samples : 60\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([True, True, True, True, True, True], device='cuda:0')\n","actual : tensor([0, 0, 0, 0, 1, 0], device='cuda:0', dtype=torch.uint8)\n","correct_ratings : 1\n","rating_accumulators : 36\n","total_rating_samples : 60\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True,  True,  True, False], device='cuda:0')\n","actual : tensor([0, 1, 0, 1, 1, 0], device='cuda:0', dtype=torch.uint8)\n","correct_ratings : 4\n","rating_accumulators : 40\n","total_rating_samples : 66\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([True, True, True, True, True, True], device='cuda:0')\n","actual : tensor([1, 1, 1, 1, 1, 0], device='cuda:0', dtype=torch.uint8)\n","correct_ratings : 5\n","rating_accumulators : 45\n","total_rating_samples : 72\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([True, True, True, True, True, True], device='cuda:0')\n","actual : tensor([1, 1, 1, 1, 1, 0], device='cuda:0', dtype=torch.uint8)\n","correct_ratings : 5\n","rating_accumulators : 50\n","total_rating_samples : 78\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([True, True, True, True, True, True, True], device='cuda:0')\n","actual : tensor([1, 0, 1, 0, 1, 1, 0], device='cuda:0', dtype=torch.uint8)\n","4\n","rating_accumulators : 25\n","total_rating_samples : 35\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([True, True, True, True, True, True], device='cuda:0')\n","actual : tensor([1, 1, 0, 1, 1, 0], device='cuda:0', dtype=torch.uint8)\n","correct_ratings : 4\n","rating_accumulators : 54\n","total_rating_samples : 84\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True,  True,  True, False], device='cuda:0')\n","actual : tensor([0, 0, 1, 1, 1, 0], device='cuda:0', dtype=torch.uint8)\n","correct_ratings : 4\n","rating_accumulators : 58\n","total_rating_samples : 90\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8)\n","4\n","rating_accumulators : 53\n","total_rating_samples : 65\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 0, 1, 0], device='cuda:0', dtype=torch.uint8)\n","2\n","rating_accumulators : 55\n","total_rating_samples : 70\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([True, True, True, True, True, True], device='cuda:0')\n","actual : tensor([1, 1, 1, 1, 1, 0], device='cuda:0', dtype=torch.uint8)\n","correct_ratings : 5\n","rating_accumulators : 63\n","total_rating_samples : 96\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True,  True,  True, False], device='cuda:0')\n","actual : tensor([0, 1, 1, 1, 1, 0], device='cuda:0', dtype=torch.uint8)\n","correct_ratings : 5\n","rating_accumulators : 68\n","total_rating_samples : 102\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([True, True, True, True, True, True], device='cuda:0')\n","actual : tensor([1, 0, 0, 0, 1, 0], device='cuda:0', dtype=torch.uint8)\n","correct_ratings : 2\n","rating_accumulators : 70\n","total_rating_samples : 108\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 0, 1, 1], device='cuda:0', dtype=torch.uint8)\n","3\n","rating_accumulators : 58\n","total_rating_samples : 75\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([True, True, True, True, True, True], device='cuda:0')\n","actual : tensor([1, 0, 1, 0, 1, 0], device='cuda:0', dtype=torch.uint8)\n","correct_ratings : 3\n","rating_accumulators : 73\n","total_rating_samples : 114\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([True, True, True, True, True, True, True], device='cuda:0')\n","actual : tensor([1, 1, 1, 0, 1, 1, 0], device='cuda:0', dtype=torch.uint8)\n","5\n","rating_accumulators : 30\n","total_rating_samples : 42\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 0, 0, 1], device='cuda:0', dtype=torch.uint8)\n","4\n","rating_accumulators : 62\n","total_rating_samples : 80\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([True, True, True, True, True, True, True], device='cuda:0')\n","actual : tensor([1, 0, 1, 0, 1, 1, 0], device='cuda:0', dtype=torch.uint8)\n","4\n","rating_accumulators : 34\n","total_rating_samples : 49\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 1, 0, 1], device='cuda:0', dtype=torch.uint8)\n","5\n","rating_accumulators : 67\n","total_rating_samples : 85\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8)\n","4\n","rating_accumulators : 71\n","total_rating_samples : 90\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([True, True, True, True, True], device='cuda:0')\n","actual : tensor([1, 1, 0, 1, 1], device='cuda:0', dtype=torch.uint8)\n","4\n","rating_accumulators : 75\n","total_rating_samples : 95\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([True, True, True, True, True, True], device='cuda:0')\n","actual : tensor([0, 1, 0, 1, 1, 0], device='cuda:0', dtype=torch.uint8)\n","correct_ratings : 3\n","rating_accumulators : 76\n","total_rating_samples : 120\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([True, True, True, True, True, True, True], device='cuda:0')\n","actual : tensor([0, 0, 1, 0, 1, 0, 0], device='cuda:0', dtype=torch.uint8)\n","2\n","rating_accumulators : 36\n","total_rating_samples : 56\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([True, True, True, True, True, True, True], device='cuda:0')\n","actual : tensor([0, 0, 1, 0, 1, 1, 0], device='cuda:0', dtype=torch.uint8)\n","3\n","rating_accumulators : 39\n","total_rating_samples : 63\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 1, 0, 1], device='cuda:0', dtype=torch.uint8)\n","5\n","rating_accumulators : 80\n","total_rating_samples : 100\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([True, True, True, True, True, True], device='cuda:0')\n","actual : tensor([0, 1, 0, 1, 1, 0], device='cuda:0', dtype=torch.uint8)\n","correct_ratings : 3\n","rating_accumulators : 79\n","total_rating_samples : 126\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8)\n","4\n","rating_accumulators : 84\n","total_rating_samples : 105\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 0, 0, 0, 1], device='cuda:0', dtype=torch.uint8)\n","3\n","rating_accumulators : 87\n","total_rating_samples : 110\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 0, 0, 1], device='cuda:0', dtype=torch.uint8)\n","4\n","rating_accumulators : 91\n","total_rating_samples : 115\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True,  True,  True, False], device='cuda:0')\n","actual : tensor([0, 1, 0, 1, 1, 0], device='cuda:0', dtype=torch.uint8)\n","correct_ratings : 4\n","rating_accumulators : 83\n","total_rating_samples : 132\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 0, 1, 1], device='cuda:0', dtype=torch.uint8)\n","3\n","rating_accumulators : 94\n","total_rating_samples : 120\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([True, True, True, True, True, True], device='cuda:0')\n","actual : tensor([0, 1, 1, 1, 1, 0], device='cuda:0', dtype=torch.uint8)\n","correct_ratings : 4\n","rating_accumulators : 87\n","total_rating_samples : 138\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([True, True, True, True, True, True, True], device='cuda:0')\n","actual : tensor([1, 0, 1, 1, 1, 1, 0], device='cuda:0', dtype=torch.uint8)\n","5\n","rating_accumulators : 44\n","total_rating_samples : 70\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 1, 0, 1], device='cuda:0', dtype=torch.uint8)\n","5\n","rating_accumulators : 99\n","total_rating_samples : 125\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True,  True,  True, False], device='cuda:0')\n","actual : tensor([0, 1, 1, 0, 1, 0], device='cuda:0', dtype=torch.uint8)\n","correct_ratings : 4\n","rating_accumulators : 91\n","total_rating_samples : 144\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8)\n","4\n","rating_accumulators : 103\n","total_rating_samples : 130\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8)\n","4\n","rating_accumulators : 107\n","total_rating_samples : 135\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([True, True, True, True, True, True], device='cuda:0')\n","actual : tensor([0, 1, 1, 1, 1, 0], device='cuda:0', dtype=torch.uint8)\n","correct_ratings : 4\n","rating_accumulators : 95\n","total_rating_samples : 150\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([0, 0, 0, 0, 1], device='cuda:0', dtype=torch.uint8)\n","2\n","rating_accumulators : 109\n","total_rating_samples : 140\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([True, True, True, True, True, True], device='cuda:0')\n","actual : tensor([1, 1, 0, 1, 1, 0], device='cuda:0', dtype=torch.uint8)\n","correct_ratings : 4\n","rating_accumulators : 99\n","total_rating_samples : 156\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8)\n","4\n","rating_accumulators : 113\n","total_rating_samples : 145\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([0, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8)\n","3\n","rating_accumulators : 116\n","total_rating_samples : 150\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([True, True, True, True, True, True], device='cuda:0')\n","actual : tensor([1, 1, 1, 1, 1, 0], device='cuda:0', dtype=torch.uint8)\n","correct_ratings : 5\n","rating_accumulators : 104\n","total_rating_samples : 162\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 0, 0, 1], device='cuda:0', dtype=torch.uint8)\n","4\n","rating_accumulators : 120\n","total_rating_samples : 155\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([True, True, True, True, True, True, True], device='cuda:0')\n","actual : tensor([1, 1, 1, 1, 1, 0, 1], device='cuda:0', dtype=torch.uint8)\n","6\n","rating_accumulators : 50\n","total_rating_samples : 77\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([0, 0, 0, 0, 1], device='cuda:0', dtype=torch.uint8)\n","2\n","rating_accumulators : 122\n","total_rating_samples : 160\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True,  True,  True, False], device='cuda:0')\n","actual : tensor([1, 1, 1, 0, 1, 1], device='cuda:0', dtype=torch.uint8)\n","correct_ratings : 4\n","rating_accumulators : 108\n","total_rating_samples : 168\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([True, True, True, True, True, True, True], device='cuda:0')\n","actual : tensor([1, 1, 1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8)\n","7\n","rating_accumulators : 57\n","total_rating_samples : 84\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8)\n","4\n","rating_accumulators : 126\n","total_rating_samples : 165\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([0, 1, 0, 0, 1], device='cuda:0', dtype=torch.uint8)\n","3\n","rating_accumulators : 129\n","total_rating_samples : 170\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([True, True, True, True, True, True, True], device='cuda:0')\n","actual : tensor([1, 1, 1, 0, 1, 1, 0], device='cuda:0', dtype=torch.uint8)\n","5\n","rating_accumulators : 62\n","total_rating_samples : 91\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True,  True,  True, False], device='cuda:0')\n","actual : tensor([0, 0, 1, 1, 1, 0], device='cuda:0', dtype=torch.uint8)\n","correct_ratings : 4\n","rating_accumulators : 112\n","total_rating_samples : 174\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","Predicted : tensor([ True,  True,  True, False,  True], device='cuda:0')\n","actual : tensor([1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8)\n","4\n","rating_accumulators : 133\n","total_rating_samples : 175\n","1 , 99\n","pose_landmarks shape: torch.Size([16, 33, 3])\n","distances_frontal shape: torch.Size([16, 528])\n","1 , 99\n","Epoch [8/1000], Validation Loss: 1.2713, Classification Accuracy: 0.7778, Rating Accuracy (Deadlift): 0.7600, Rating Accuracy (Squat): 0.6437, Rating Accuracy (Lunges): 0.6813\n","Early stopping triggered.\n","Training complete.\n"]}],"source":["# Initialize the model\n","dual_combined_model = Dual_Combined_Model()\n","rating_model = DeepClassificationWithRatingModel()\n","\n","print(device)\n","\n","# Train the model\n","train_combined_model(dual_combined_model, rating_model, dataloader, eval_dataloader, epochs=1000, lr=1e-4, device=device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R-28a40QuXbR","outputId":"075bd4b4-2922-4bd8-cc33-93d76e415e5d"},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[26], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_model_epoch_1.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m criteria_model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_rating_model_epoch_1.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----\u003e 5\u001b[0m dual_combined_model \u001b[38;5;241m=\u001b[39m \u001b[43mDual_Combined_Model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m rating_model \u001b[38;5;241m=\u001b[39m DeepClassificationWithRatingModel()\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Load the saved model weights\u001b[39;00m\n","Cell \u001b[1;32mIn[16], line 11\u001b[0m, in \u001b[0;36mDual_Combined_Model.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28msuper\u001b[39m(Dual_Combined_Model, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Initialize two instances of Combined_Video_Pose_Model\u001b[39;00m\n\u001b[1;32m---\u003e 11\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_1 \u001b[38;5;241m=\u001b[39m \u001b[43mCombined_Video_Pose_Model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_2 \u001b[38;5;241m=\u001b[39m Combined_Video_Pose_Model()\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Fully connected layers for classification\u001b[39;00m\n","Cell \u001b[1;32mIn[15], line 11\u001b[0m, in \u001b[0;36mCombined_Video_Pose_Model.__init__\u001b[1;34m(self, video_hidden_size, pose_hidden_size, combined_hidden_size, hidden_layer_size, dropout_rate)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28msuper\u001b[39m(Combined_Video_Pose_Model, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Video model (returns a 2048-dimensional feature vector)\u001b[39;00m\n\u001b[1;32m---\u003e 11\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvideo_model \u001b[38;5;241m=\u001b[39m \u001b[43mVideo_Model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvideo_hidden_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Pose model (returns a 2048-dimensional feature vector)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpose_model \u001b[38;5;241m=\u001b[39m Pose_Model(final_size\u001b[38;5;241m=\u001b[39mpose_hidden_size)\n","Cell \u001b[1;32mIn[13], line 19\u001b[0m, in \u001b[0;36mVideo_Model.__init__\u001b[1;34m(self, pretrained_model_name, hidden_size)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28msuper\u001b[39m(Video_Model, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Load the pretrained VideoMAE model\u001b[39;00m\n\u001b[1;32m---\u003e 19\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvideomae \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForPreTraining\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Pooling layer to aggregate the patch embeddings (mean pooling)\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooling \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mAdaptiveAvgPool1d(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Converts [batch_size, 782, 1536] -\u003e [batch_size, 1536]\u001b[39;00m\n","File \u001b[1;32md:\\Courses\\ANA\\envs\\ahmed\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:471\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    470\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[1;32m--\u003e 471\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    472\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    473\u001b[0m     )\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    476\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    477\u001b[0m )\n","File \u001b[1;32md:\\Courses\\ANA\\envs\\ahmed\\lib\\site-packages\\transformers\\modeling_utils.py:2629\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   2626\u001b[0m     init_contexts\u001b[38;5;241m.\u001b[39mappend(init_empty_weights())\n\u001b[0;32m   2628\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ContextManagers(init_contexts):\n\u001b[1;32m-\u003e 2629\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(config, \u001b[38;5;241m*\u001b[39mmodel_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[0;32m   2631\u001b[0m \u001b[38;5;66;03m# Check first if we are `from_pt`\u001b[39;00m\n\u001b[0;32m   2632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_keep_in_fp32_modules:\n","File \u001b[1;32md:\\Courses\\ANA\\envs\\ahmed\\lib\\site-packages\\transformers\\models\\videomae\\modeling_videomae.py:768\u001b[0m, in \u001b[0;36mVideoMAEForPreTraining.__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m    766\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder_to_decoder \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(config\u001b[38;5;241m.\u001b[39mhidden_size, config\u001b[38;5;241m.\u001b[39mdecoder_hidden_size, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    767\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_token \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mParameter(torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, config\u001b[38;5;241m.\u001b[39mdecoder_hidden_size))\n\u001b[1;32m--\u003e 768\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mget_sinusoid_encoding_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    769\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvideomae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_patches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder_hidden_size\u001b[49m\n\u001b[0;32m    770\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder \u001b[38;5;241m=\u001b[39m VideoMAEDecoder(config, num_patches\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvideomae\u001b[38;5;241m.\u001b[39membeddings\u001b[38;5;241m.\u001b[39mnum_patches)\n\u001b[0;32m    774\u001b[0m \u001b[38;5;66;03m# Initialize weights and apply final processing\u001b[39;00m\n","File \u001b[1;32md:\\Courses\\ANA\\envs\\ahmed\\lib\\site-packages\\transformers\\models\\videomae\\modeling_videomae.py:114\u001b[0m, in \u001b[0;36mget_sinusoid_encoding_table\u001b[1;34m(n_position, d_hid)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_position_angle_vec\u001b[39m(position):\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [position \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39mpower(\u001b[38;5;241m10000\u001b[39m, \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m (hid_j \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m/\u001b[39m d_hid) \u001b[38;5;28;01mfor\u001b[39;00m hid_j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(d_hid)]\n\u001b[1;32m--\u003e 114\u001b[0m sinusoid_table \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([get_position_angle_vec(pos_i) \u001b[38;5;28;01mfor\u001b[39;00m pos_i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_position)])\n\u001b[0;32m    115\u001b[0m sinusoid_table[:, \u001b[38;5;241m0\u001b[39m::\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msin(sinusoid_table[:, \u001b[38;5;241m0\u001b[39m::\u001b[38;5;241m2\u001b[39m])  \u001b[38;5;66;03m# dim 2i\u001b[39;00m\n\u001b[0;32m    116\u001b[0m sinusoid_table[:, \u001b[38;5;241m1\u001b[39m::\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcos(sinusoid_table[:, \u001b[38;5;241m1\u001b[39m::\u001b[38;5;241m2\u001b[39m])  \u001b[38;5;66;03m# dim 2i+1\u001b[39;00m\n","File \u001b[1;32md:\\Courses\\ANA\\envs\\ahmed\\lib\\site-packages\\transformers\\models\\videomae\\modeling_videomae.py:114\u001b[0m, in \u001b[0;36m\u003clistcomp\u003e\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_position_angle_vec\u001b[39m(position):\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [position \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39mpower(\u001b[38;5;241m10000\u001b[39m, \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m (hid_j \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m/\u001b[39m d_hid) \u001b[38;5;28;01mfor\u001b[39;00m hid_j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(d_hid)]\n\u001b[1;32m--\u003e 114\u001b[0m sinusoid_table \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mget_position_angle_vec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos_i\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m pos_i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_position)])\n\u001b[0;32m    115\u001b[0m sinusoid_table[:, \u001b[38;5;241m0\u001b[39m::\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msin(sinusoid_table[:, \u001b[38;5;241m0\u001b[39m::\u001b[38;5;241m2\u001b[39m])  \u001b[38;5;66;03m# dim 2i\u001b[39;00m\n\u001b[0;32m    116\u001b[0m sinusoid_table[:, \u001b[38;5;241m1\u001b[39m::\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcos(sinusoid_table[:, \u001b[38;5;241m1\u001b[39m::\u001b[38;5;241m2\u001b[39m])  \u001b[38;5;66;03m# dim 2i+1\u001b[39;00m\n","File \u001b[1;32md:\\Courses\\ANA\\envs\\ahmed\\lib\\site-packages\\transformers\\models\\videomae\\modeling_videomae.py:112\u001b[0m, in \u001b[0;36mget_sinusoid_encoding_table.\u003clocals\u003e.get_position_angle_vec\u001b[1;34m(position)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_position_angle_vec\u001b[39m(position):\n\u001b[1;32m--\u003e 112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [position \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39mpower(\u001b[38;5;241m10000\u001b[39m, \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m (hid_j \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m/\u001b[39m d_hid) \u001b[38;5;28;01mfor\u001b[39;00m hid_j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(d_hid)]\n","File \u001b[1;32md:\\Courses\\ANA\\envs\\ahmed\\lib\\site-packages\\transformers\\models\\videomae\\modeling_videomae.py:112\u001b[0m, in \u001b[0;36m\u003clistcomp\u003e\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_position_angle_vec\u001b[39m(position):\n\u001b[1;32m--\u003e 112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [position \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39mpower(\u001b[38;5;241m10000\u001b[39m, \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m (hid_j \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m/\u001b[39m d_hid) \u001b[38;5;28;01mfor\u001b[39;00m hid_j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(d_hid)]\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Define the path to the saved model weights\n","model_path = \"best_model_epoch_1.pt\"\n","criteria_model_path = \"best_rating_model_epoch_1.pt\"\n","\n","dual_combined_model = Dual_Combined_Model()\n","rating_model = DeepClassificationWithRatingModel()\n","\n","# Load the saved model weights\n","dual_combined_model.load_state_dict(torch.load(model_path))\n","rating_model.load_state_dict(torch.load(criteria_model_path))\n","\n","print(device)\n","\n","# Continue training the model\n","train_combined_model(dual_combined_model, rating_model, dataloader, eval_dataloader,\n","                     epochs=1000, lr=1e-4, device=device)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":86042,"status":"ok","timestamp":1734089202972,"user":{"displayName":"ai research","userId":"07349987832510586956"},"user_tz":-120},"id":"hcJUojk1vFCu","outputId":"dc965de7-c45e-43c5-f0c5-7b5cb657457c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2145,"status":"ok","timestamp":1734088833587,"user":{"displayName":"ai research","userId":"07349987832510586956"},"user_tz":-120},"id":"we04hFbBv2HZ","outputId":"b66577d6-f2d8-49e1-fc01-ed2c636b0c67"},"outputs":[{"name":"stdout","output_type":"stream","text":["drive  sample_data\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1734088836414,"user":{"displayName":"ai research","userId":"07349987832510586956"},"user_tz":-120},"id":"LwutYdOnv3k3","outputId":"fd6e75ea-11f5-47bf-8ff6-1f1316fa7092"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content\n"]}],"source":["!pwd"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eJuCirhnv5sj"},"outputs":[],"source":["\"/content/drive/MyDrive/Vision_GYM_Research/Data\""]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":0}